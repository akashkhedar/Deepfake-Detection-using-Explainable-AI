# Deepfake Detection using Explainable AI

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.8%2B-blue)
![React](https://img.shields.io/badge/react-19.1.1-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.100%2B-green)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange)
![Material--UI](https://img.shields.io/badge/Material--UI-7.3.2-blue)

## üìã Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [System Architecture](#-system-architecture)
- [Dataset Information](#-dataset-information)
- [Project Structure](#-project-structure)
- [Technical Stack](#-technical-stack)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Usage](#-usage)
- [API Documentation](#-api-documentation)
- [Frontend Components](#-frontend-components)
- [Backend Architecture](#-backend-architecture)
- [Model Details](#-model-details)
- [Explainability Features](#-explainability-features)
- [Performance Metrics](#-performance-metrics)
- [Utilities & Tools](#-utilities--tools)
- [Testing & Validation](#-testing--validation)
- [Deployment](#-deployment)
- [Troubleshooting](#-troubleshooting)
- [Contributing](#-contributing)
- [License](#-license)
- [Acknowledgments](#-acknowledgments)
- [Future Enhancements](#-future-enhancements)
- [Contact](#-contact)

## üéØ Overview

An **enterprise-grade deepfake detection system** powered by an ensemble of state-of-the-art deep learning models with comprehensive explainable AI capabilities. This project combines multiple CNN architectures with GradCAM visualization and AI-powered natural language explanations to detect manipulated images with high accuracy, transparency, and user trust.

**Key Highlights:**

- ü§ñ **5-Model Ensemble Architecture**: Combines ResNet50, ResNet152V2, InceptionResNetV2, Xception, and EfficientNetB4
- üîç **Advanced Explainable AI**: GradCAM heatmaps + Google Gemini 2.5 Flash-powered natural language explanations
- üåê **Modern Web Interface**: React 19 + Material-UI with responsive design and real-time analysis
- ‚ö° **High Performance Backend**: FastAPI with async support and GPU acceleration
- üìä **Massive Dataset**: 190,335+ verified images (real and AI-generated)
- üé® **Interactive Visualizations**: Real-time heatmap overlays showing model attention regions
- üì¶ **Production Ready**: Docker support, comprehensive logging, error handling, and monitoring
- üîí **Secure & Scalable**: CORS configuration, environment-based secrets, scalable architecture

## üåü Features

### Core Capabilities

#### 1. **Multi-Model Ensemble Architecture**

- **5 Powerful CNN Models** working in concert:

  - **ResNet50** (25.6M parameters) - Residual learning for deep networks, 224√ó224 input
  - **ResNet152V2** (60.2M parameters) - Deeper residual architecture, 224√ó224 input
  - **InceptionResNetV2** (55.8M parameters) - Multi-scale feature extraction, 299√ó299 input
  - **Xception** (22.9M parameters) - Depthwise separable convolutions, 299√ó299 input
  - **EfficientNetB4** (19.3M parameters) - Compound scaling optimization, 380√ó380 input

- **Model Performance Metrics**:

| Model                 | Train Accuracy | Train Loss | Val Accuracy | Val Loss |
| --------------------- | -------------- | ---------- | ------------ | -------- |
| **EfficientNetB4**    | **99.82%**     | 0.0050     | 98.68%       | 0.0787   |
| **InceptionResNetV2** | **99.62%**     | 0.0093     | **98.88%**   | 0.0441   |
| **ResNet152V2**       | **99.72%**     | 0.0085     | 98.87%       | 0.0506   |
| **Xception**          | 99.41%         | 0.0048     | 98.79%       | 0.0658   |
| **ResNet50**          | 99.18%         | 0.0206     | 98.57%       | 0.0438   |
| **Average**           | **99.55%**     | 0.0096     | **98.76%**   | 0.0566   |

- All models achieve >98.5% validation accuracy
- Average generalization gap: 0.79% (minimal overfitting)
- Best validation performer: InceptionResNetV2 (98.88%)
- Highest training accuracy: EfficientNetB4 (99.82%)
- Lowest training loss: Xception (0.0048)

- **Ensemble Prediction**: Weighted averaging of softmax probabilities across all models
- **Individual Model Selection**: Test specific models independently or compare results
- **Robust Decision Making**: Reduces individual model biases through diversity
- **Dynamic Model Loading**: Selective model loading based on configuration

#### 2. **Explainable AI (XAI) Framework**

- **GradCAM Heatmap Visualization**:
  - Gradient-weighted Class Activation Mapping for visual explanations
  - Shows which image regions influenced the model's decision
  - Color-coded attention maps (red/yellow = high attention, blue = low attention)
  - Weighted fusion of heatmaps from all ensemble models
  - Real-time overlay generation with 40% heatmap + 60% original image composition
  - Model-specific target layers for optimal activation extraction
- **AI-Generated Natural Language Explanations**:
  - Powered by Google Gemini 2.5 Flash multimodal API
  - Context-aware explanations based on prediction label and heatmap
  - Human-readable justifications for each decision in 2-3 sentences
  - Automatic fallback to generic explanations if API unavailable
  - Vision-language integration for deeper understanding
- **Per-Model Confidence Breakdown**:
  - Individual confidence scores for each model
  - Ensemble confidence aggregation
  - Real vs Fake probability distribution
  - Complete transparency in decision-making process
  - JSON-formatted detailed metrics

#### 3. **Modern Web Interface**

- **Responsive React-based UI**:
  - Mobile-first design with adaptive layouts for all screen sizes
  - Dark theme optimized for visual comfort and professional appearance
  - Material-UI 7.3.2 components for consistent, polished interface
  - Real-time state management with React hooks (useImageAnalysis)
  - Smooth animations and transitions for better UX
- **Interactive Features**:
  - Drag-and-drop image upload with visual feedback
  - File browser integration with image format validation
  - Live analysis progress indicators with loading states
  - Instant result visualization without page reloads
  - Model selector dropdown (Ensemble + 5 individual models)
  - Reset functionality to analyze multiple images
- **Rich Visual Feedback**:
  - Original image display with responsive borders
  - Side-by-side heatmap comparison layout
  - Color-coded prediction badges (Green = Real, Red = Fake, Orange = Error)
  - Confidence percentage displays with precision
  - Detailed explanation cards with contextual styling
  - Smooth state transitions and animations

#### 4. **Production-Ready Backend**

- **FastAPI Framework**:
  - Async/await request handling for high concurrent performance
  - Auto-generated OpenAPI documentation (Swagger UI at /docs)
  - Type hints and automatic data validation with Pydantic
  - RESTful API design following best practices
  - Built-in request/response schemas
- **Advanced Features**:
  - CORS middleware for secure cross-origin requests
  - GPU/CPU automatic device detection with fallback
  - Batch model loading on application startup
  - Comprehensive error handling with proper HTTP status codes
  - Structured logging with log levels (INFO, WARNING, ERROR)
  - Health check and status monitoring endpoints
  - Model availability checking before inference
- **Performance Optimizations**:
  - Model caching in memory (singleton pattern)
  - Efficient image preprocessing pipelines with transforms
  - Parallel GradCAM computation across models
  - Optimized tensor operations with PyTorch JIT (where applicable)
  - Minimal memory footprint with cleanup
  - Fast multipart/form-data parsing

#### 5. **Dataset Management**

- **Comprehensive Validation Tools** (`check_dataset.py`):
  - Automatic image corruption detection with PIL verification
  - Image integrity verification (file header checks)
  - Size distribution analysis across splits
  - Class balance statistics and imbalance detection
  - Sample grid generation for visual inspection
  - JSON summary export for documentation
  - Progress bars with tqdm for large datasets
- **Flexible Data Organization**:
  - Train/Validation/Test split structure (73.5% / 20.7% / 5.7%)
  - Real/Fake binary classification folders
  - Standardized 256√ó256 resolution across all images
  - Zero corrupted images verified (100% integrity)
  - Hierarchical directory structure for scalability

#### 6. **Developer Experience**

- **Git LFS Integration**:
  - Efficient handling of large model files (~1.66 GB total)
  - Automatic tracking for `.pth`, `.pt`, `.h5`, `.onnx`, `.pkl` files
  - Pointer files in repo, actual files in LFS storage
  - Simple clone-and-go workflow
- **Comprehensive Documentation**:
  - README.md with complete project overview
  - SETUP_GUIDE.md with step-by-step installation
  - QUICK_REFERENCE.md for common commands
  - Backend/DATASET.md for dataset download
  - Backend/models/README.md for model files
  - GIT_LFS_IMPLEMENTATION.md for LFS details
  - Inline code comments and docstrings
- **Environment Configuration**:
  - `.env` support for secrets and configuration
  - Environment variable validation
  - Separate configs for dev/prod environments
  - Configurable model loading (all or selective)
- **Logging & Debugging**:
  - Detailed logs for monitoring and debugging
  - Configurable log levels
  - Request/response logging
  - Error stack traces
  - Performance metrics tracking
- **Code Quality**:
  - Type hints throughout codebase
  - Modular architecture with clear separation
  - Single Responsibility Principle
  - DRY (Don't Repeat Yourself) practices
  - Consistent naming conventions

## üèõÔ∏è System Architecture

### High-Level Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         Frontend Layer                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  React 19 + Vite + Material-UI                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Port: 5173 (Development) / 4173 (Preview)               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ App.jsx (Router + Root Component)                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ HomePage.jsx (Theme Provider + Dark Mode)             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Navbar.jsx (GitHub Navigation)                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ ModelSection.jsx (Main Analysis Interface)            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ useImageAnalysis.js (Custom Hook - State Management)  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Sub-Components:                                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ ImageUploadArea.jsx (Drag & Drop + File Picker)       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ ImageDisplay.jsx (Original Image Display)             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ HeatmapDisplay.jsx (GradCAM Visualization)            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ ExplanationBox.jsx (AI Explanation Rendering)         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ RealImageMessage.jsx (Success State Display)          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ WaitingState.jsx (Loading Indicators)                 ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ HTTP/REST API (JSON + Base64)
                            ‚îÇ CORS-enabled, async requests
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Backend Layer                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  FastAPI + Uvicorn ASGI Server                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Port: 8000 (Configurable)                               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ main.py (API Endpoints, Routing, Middleware)          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    - GET  /            (Health Check)                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    - GET  /models/     (List Loaded Models)              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    - GET  /status/     (System Status & Device Info)     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    - POST /predict/    (Image Analysis Endpoint)         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ service.py (Core Logic)                               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    - ModelManager Class (Singleton)                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    - Model Loading & Checkpoint Management               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    - Inference Orchestration                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    - GradCAM Generation                                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    - Gemini API Integration                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ CORS Middleware (Cross-Origin Security)               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Error Handlers & Exception Logging                    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Deep Learning Layer                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  PyTorch 2.0+ with CUDA/CPU Support                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Device: Auto-detect (CUDA if available, else CPU)       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ ResNet50   ‚îÇ ResNet152V2  ‚îÇ Inception   ‚îÇ Xception ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ            ‚îÇ              ‚îÇ ResNetV2    ‚îÇ          ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Input:     ‚îÇ Input:       ‚îÇ Input:      ‚îÇ Input:   ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ 224√ó224    ‚îÇ 224√ó224      ‚îÇ 299√ó299     ‚îÇ 299√ó299  ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ            ‚îÇ              ‚îÇ             ‚îÇ          ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Size:      ‚îÇ Size:        ‚îÇ Size:       ‚îÇ Size:    ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ ~98 MB     ‚îÇ ~236 MB      ‚îÇ ~215 MB     ‚îÇ ~88 MB   ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ            ‚îÇ              ‚îÇ             ‚îÇ          ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Params:    ‚îÇ Params:      ‚îÇ Params:     ‚îÇ Params:  ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ 25.6M      ‚îÇ 60.2M        ‚îÇ 55.8M       ‚îÇ 22.9M    ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ            ‚îÇ              ‚îÇ             ‚îÇ          ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Target:    ‚îÇ Target:      ‚îÇ Target:     ‚îÇ Target:  ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ layer4[-1] ‚îÇ layer4[-1]   ‚îÇ Mixed_7c    ‚îÇ block4   ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ .conv2     ‚îÇ .conv2       ‚îÇ (conv2d_7b) ‚îÇ          ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ EfficientNetB4                                       ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Input: 380√ó380 | Size: ~75 MB | Params: 19.3M       ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Target: blocks[-1][-1].conv_pwl                      ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Preprocessing Pipeline:                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Resize to model-specific dimensions                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Convert to Tensor                                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Normalize with ImageNet stats                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    Mean: [0.485, 0.456, 0.406]                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    Std:  [0.229, 0.224, 0.225]                           ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   Explainability Layer                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  TorchCAM (GradCAM Implementation)                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Target layer extraction per model architecture        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Gradient computation with backward pass               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Activation map generation (class-specific)            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ CAM normalization and resizing to original size       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Weighted heatmap fusion (confidence-based weights)    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Overlay composition with OpenCV:                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    - Apply JET colormap to normalized CAM                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    - Blend: 40% heatmap + 60% original image             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    - Encode to base64 PNG for transmission               ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Google Gemini 2.5 Flash API                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Natural language explanation generation               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Context-aware reasoning based on prediction label     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Vision-language multimodal integration                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Input: Prediction label + Heatmap overlay (base64)    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Output: 2-3 sentence human-readable explanation       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Fallback: Generic explanation if API fails            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Rate limiting & error handling                        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Data Flow Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ User Action     ‚îÇ
‚îÇ Upload Image    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Frontend Processing          ‚îÇ
‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ     ‚îÇ
‚îÇ 1. File validation           ‚îÇ
‚îÇ    ‚Ä¢ Type check (image/*)    ‚îÇ
‚îÇ    ‚Ä¢ Size limit check        ‚îÇ
‚îÇ 2. FileReader API            ‚îÇ
‚îÇ    ‚Ä¢ Convert to base64       ‚îÇ
‚îÇ    ‚Ä¢ Generate preview URL    ‚îÇ
‚îÇ 3. State Management          ‚îÇ
‚îÇ    ‚Ä¢ Update selectedImage    ‚îÇ
‚îÇ    ‚Ä¢ Set isAnalyzing = true  ‚îÇ
‚îÇ    ‚Ä¢ Clear previous results  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ HTTP POST Request            ‚îÇ
‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ     ‚îÇ
‚îÇ URL: /predict/               ‚îÇ
‚îÇ Query: ?model=<name>         ‚îÇ
‚îÇ        (optional)            ‚îÇ
‚îÇ Body: multipart/form-data    ‚îÇ
‚îÇ   file: <binary image data>  ‚îÇ
‚îÇ Headers:                     ‚îÇ
‚îÇ   Content-Type:              ‚îÇ
‚îÇ     multipart/form-data      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Backend API Endpoint                 ‚îÇ
‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ     ‚îÇ
‚îÇ @app.post("/predict/")               ‚îÇ
‚îÇ 1. Receive UploadFile                ‚îÇ
‚îÇ 2. Read file bytes: await file.read()‚îÇ
‚îÇ 3. Open with PIL: Image.open()       ‚îÇ
‚îÇ 4. Convert to RGB: .convert("RGB")   ‚îÇ
‚îÇ 5. Extract model param from query    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Model Manager Dispatcher              ‚îÇ
‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ     ‚îÇ
‚îÇ Route based on model parameter:       ‚îÇ
‚îÇ                                       ‚îÇ
‚îÇ if model specified:                   ‚îÇ
‚îÇ   ‚Üí predict_single(model, image)      ‚îÇ
‚îÇ else:                                 ‚îÇ
‚îÇ   ‚Üí predict_ensemble(image)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                 ‚îÇ                ‚îÇ
        ‚ñº                 ‚ñº                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇSingle Model  ‚îÇ  ‚îÇ Ensemble     ‚îÇ  ‚îÇ Ensemble     ‚îÇ
‚îÇPrediction    ‚îÇ  ‚îÇ Model 1      ‚îÇ  ‚îÇ Model 2-5    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                 ‚îÇ                ‚îÇ
       ‚îÇ                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                          ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ For Each Model (Parallel in Ensemble):  ‚îÇ
‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ     ‚îÇ
‚îÇ 1. Get model-specific preprocessor      ‚îÇ
‚îÇ    ‚Ä¢ Resize to input dimensions          ‚îÇ
‚îÇ    ‚Ä¢ ToTensor transformation             ‚îÇ
‚îÇ    ‚Ä¢ Normalize with ImageNet stats       ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ 2. Prepare input tensor                 ‚îÇ
‚îÇ    ‚Ä¢ Add batch dimension: unsqueeze(0)   ‚îÇ
‚îÇ    ‚Ä¢ Move to device: .to(device)         ‚îÇ
‚îÇ    ‚Ä¢ Enable gradients: requires_grad_()  ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ 3. Forward pass through model            ‚îÇ
‚îÇ    ‚Ä¢ output = model(input_tensor)        ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ 4. Compute probabilities                ‚îÇ
‚îÇ    ‚Ä¢ For Xception: direct sigmoid output ‚îÇ
‚îÇ    ‚Ä¢ For others: F.softmax(output, dim=1)‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ 5. Handle class inversion                ‚îÇ
‚îÇ    ‚Ä¢ InceptionResNet & EfficientNet:     ‚îÇ
‚îÇ      Index 0 = Real, Index 1 = Fake      ‚îÇ
‚îÇ    ‚Ä¢ Others:                             ‚îÇ
‚îÇ      Index 0 = Fake, Index 1 = Real      ‚îÇ
‚îÇ    ‚Ä¢ Unify to [Fake, Real] format        ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ 6. Determine prediction                 ‚îÇ
‚îÇ    ‚Ä¢ pred_idx = argmax(probabilities)    ‚îÇ
‚îÇ    ‚Ä¢ label = "Real" if pred_idx==1       ‚îÇ
‚îÇ              else "Fake"                 ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ 7. Extract GradCAM                       ‚îÇ
‚îÇ    ‚Ä¢ cam_extractor = GradCAM(model)      ‚îÇ
‚îÇ    ‚Ä¢ Determine target class index        ‚îÇ
‚îÇ      (handle model-specific inversions)  ‚îÇ
‚îÇ    ‚Ä¢ cam = cam_extractor(class_idx, out) ‚îÇ
‚îÇ    ‚Ä¢ Normalize CAM to [0, 1]             ‚îÇ
‚îÇ    ‚Ä¢ Resize to original image size       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Aggregate Results (Ensemble Only)        ‚îÇ
‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ    ‚îÇ
‚îÇ 1. Collect all unified probabilities     ‚îÇ
‚îÇ    ‚Ä¢ Stack: [[Fake, Real], ...]          ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ 2. Average probabilities                 ‚îÇ
‚îÇ    ‚Ä¢ ensemble_probs = mean(all_probs)    ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ 3. Determine ensemble prediction         ‚îÇ
‚îÇ    ‚Ä¢ pred_idx = argmax(ensemble_probs)   ‚îÇ
‚îÇ    ‚Ä¢ label = "Real" if pred_idx==1       ‚îÇ
‚îÇ              else "Fake"                 ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ 4. Fuse GradCAMs                         ‚îÇ
‚îÇ    ‚Ä¢ weights = confidence per model      ‚îÇ
‚îÇ    ‚Ä¢ Normalize weights: sum = 1.0        ‚îÇ
‚îÇ    ‚Ä¢ Weighted sum of CAMs                ‚îÇ
‚îÇ    ‚Ä¢ ensemble_cam = Œ£(weight_i * cam_i)  ‚îÇ
‚îÇ    ‚Ä¢ Normalize final CAM                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Generate Heatmap Overlay                 ‚îÇ
‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ    ‚îÇ
‚îÇ 1. Denormalize input image               ‚îÇ
‚îÇ    ‚Ä¢ Reverse ImageNet normalization      ‚îÇ
‚îÇ    ‚Ä¢ Clip to [0, 1] range                ‚îÇ
‚îÇ    ‚Ä¢ Resize to original dimensions       ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ 2. Apply colormap to CAM                 ‚îÇ
‚îÇ    ‚Ä¢ Convert CAM to uint8: cam * 255     ‚îÇ
‚îÇ    ‚Ä¢ Apply JET colormap (OpenCV)         ‚îÇ
‚îÇ    ‚Ä¢ Convert BGR to RGB                  ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ 3. Create overlay                        ‚îÇ
‚îÇ    ‚Ä¢ Blend: 0.4 * heatmap + 0.6 * image  ‚îÇ
‚îÇ    ‚Ä¢ Clip to [0, 1]                      ‚îÇ
‚îÇ    ‚Ä¢ Convert to uint8: * 255             ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ 4. Encode to base64                      ‚îÇ
‚îÇ    ‚Ä¢ imencode to PNG format              ‚îÇ
‚îÇ    ‚Ä¢ base64 encode buffer                ‚îÇ
‚îÇ    ‚Ä¢ Decode to UTF-8 string              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Generate AI Explanation (if Fake)        ‚îÇ
‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ    ‚îÇ
‚îÇ if prediction == "Fake":                 ‚îÇ
‚îÇ   1. Check Gemini API availability       ‚îÇ
‚îÇ   2. Prepare prompt:                     ‚îÇ
‚îÇ      "Model predicted {label}.           ‚îÇ
‚îÇ       Heatmap shows attention regions.   ‚îÇ
‚îÇ       Explain why in 2-3 sentences."     ‚îÇ
‚îÇ   3. Call Gemini API:                    ‚îÇ
‚îÇ      ‚Ä¢ Model: gemini-2.5-flash           ‚îÇ
‚îÇ      ‚Ä¢ Input: [prompt, heatmap_base64]   ‚îÇ
‚îÇ   4. Extract explanation text            ‚îÇ
‚îÇ   5. Fallback on error:                  ‚îÇ
‚îÇ      Generic message                     ‚îÇ
‚îÇ else:                                    ‚îÇ
‚îÇ   Generic "Real" explanation             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Construct JSON Response                  ‚îÇ
‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ    ‚îÇ
‚îÇ Single Model Response:                   ‚îÇ
‚îÇ {                                        ‚îÇ
‚îÇ   "model": "resnet50",                   ‚îÇ
‚îÇ   "prediction": "Fake",                  ‚îÇ
‚îÇ   "confidence": 0.9532,                  ‚îÇ
‚îÇ   "probabilities": {                     ‚îÇ
‚îÇ     "real": 0.0468,                      ‚îÇ
‚îÇ     "fake": 0.9532                       ‚îÇ
‚îÇ   },                                     ‚îÇ
‚îÇ   "heatmap": "data:image/png;base64,...",‚îÇ
‚îÇ   "explanation": "The model detected..." ‚îÇ
‚îÇ }                                        ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ Ensemble Response:                       ‚îÇ
‚îÇ {                                        ‚îÇ
‚îÇ   "ensemble_prediction": "Fake",         ‚îÇ
‚îÇ   "ensemble_confidence": 0.9621,         ‚îÇ
‚îÇ   "ensemble_probabilities": {            ‚îÇ
‚îÇ     "real": 0.0379,                      ‚îÇ
‚îÇ     "fake": 0.9621                       ‚îÇ
‚îÇ   },                                     ‚îÇ
‚îÇ   "per_model_confidences": {             ‚îÇ
‚îÇ     "resnet50": {"real": 0.05, ...},     ‚îÇ
‚îÇ     "resnet152": {"real": 0.03, ...},    ‚îÇ
‚îÇ     ...                                  ‚îÇ
‚îÇ   },                                     ‚îÇ
‚îÇ   "heatmap": "data:image/png;base64,...",‚îÇ
‚îÇ   "explanation": "The ensemble..."       ‚îÇ
‚îÇ }                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Frontend State Update                    ‚îÇ
‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ    ‚îÇ
‚îÇ 1. Parse JSON response                   ‚îÇ
‚îÇ 2. Extract data:                         ‚îÇ
‚îÇ    ‚Ä¢ prediction = response.prediction    ‚îÇ
‚îÇ      or response.ensemble_prediction     ‚îÇ
‚îÇ    ‚Ä¢ confidence = response.confidence    ‚îÇ
‚îÇ      or response.ensemble_confidence     ‚îÇ
‚îÇ    ‚Ä¢ heatmap = response.heatmap          ‚îÇ
‚îÇ    ‚Ä¢ explanation = response.explanation  ‚îÇ
‚îÇ 3. Update React state:                   ‚îÇ
‚îÇ    ‚Ä¢ setPrediction(prediction)           ‚îÇ
‚îÇ    ‚Ä¢ setConfidence(confidence)           ‚îÇ
‚îÇ    ‚Ä¢ setHeatmapUrl(heatmap)              ‚îÇ
‚îÇ    ‚Ä¢ setExplanation(explanation)         ‚îÇ
‚îÇ    ‚Ä¢ setIsAnalyzing(false)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ UI Rendering                             ‚îÇ
‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ    ‚îÇ
‚îÇ ‚Ä¢ ImageDisplay: Show original image      ‚îÇ
‚îÇ ‚Ä¢ HeatmapDisplay: Render heatmap overlay ‚îÇ
‚îÇ   - Color-coded badge (Red/Green)        ‚îÇ
‚îÇ   - Confidence percentage                ‚îÇ
‚îÇ ‚Ä¢ ExplanationBox: Display AI explanation ‚îÇ
‚îÇ   - Contextual styling based on result   ‚îÇ
‚îÇ ‚Ä¢ Animation: Smooth transitions          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìä Dataset Information

### Dataset Overview

The models are trained on a comprehensive, large-scale dataset of real and AI-generated face images sourced from Kaggle, specifically curated for deepfake detection research.

**Dataset Source**: [140k Real and Fake Faces - Kaggle](https://www.kaggle.com/datasets/xhlulu/140k-real-and-fake-faces)

### Comprehensive Dataset Statistics

| Split      | Fake Images | Real Images | Total       | Percentage | Avg per Class |
| ---------- | ----------- | ----------- | ----------- | ---------- | ------------- |
| Training   | 70,001      | 70,001      | 140,002     | 73.54%     | 70,001        |
| Validation | 19,641      | 19,787      | 39,428      | 20.71%     | 19,714        |
| Test       | 5,492       | 5,413       | 10,905      | 5.73%      | 5,452.5       |
| **Total**  | **95,134**  | **95,201**  | **190,335** | **100%**   | **95,167.5**  |

**Class Balance**: 99.97% balanced (95,134 fake vs 95,201 real = 49.98% vs 50.02%)

### Technical Specifications

| Specification        | Value             | Description                    |
| -------------------- | ----------------- | ------------------------------ |
| **Image Resolution** | 256√ó256 pixels    | Standardized across all images |
| **Color Space**      | RGB (3 channels)  | Full color information         |
| **Bit Depth**        | 8-bit per channel | Standard image encoding        |
| **File Format**      | JPEG              | Compressed format              |
| **Compression**      | Variable quality  | Optimized file size            |
| **Total Storage**    | ~5.2 GB           | Complete dataset size          |
| **Image Integrity**  | 100% verified     | Zero corrupted files           |
| **Missing Files**    | 0                 | Complete dataset               |
| **Duplicate Files**  | 0                 | All unique images              |

### Dataset Structure

```
dataset/
‚îú‚îÄ‚îÄ Train/                           # Training Set (73.54%)
‚îÇ   ‚îú‚îÄ‚îÄ Fake/                        # 70,001 AI-generated faces
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fake_0.jpg               # StyleGAN generated
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fake_1.jpg               # ProGAN generated
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fake_2.jpg               # Various GAN architectures
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fake_70000.jpg
‚îÇ   ‚îî‚îÄ‚îÄ Real/                        # 70,001 authentic faces
‚îÇ       ‚îú‚îÄ‚îÄ real_0.jpg               # FFHQ dataset
‚îÇ       ‚îú‚îÄ‚îÄ real_1.jpg               # CelebA dataset
‚îÇ       ‚îú‚îÄ‚îÄ real_2.jpg               # Various sources
‚îÇ       ‚îú‚îÄ‚îÄ ...
‚îÇ       ‚îî‚îÄ‚îÄ real_70000.jpg
‚îÇ
‚îú‚îÄ‚îÄ Validation/                      # Validation Set (20.71%)
‚îÇ   ‚îú‚îÄ‚îÄ Fake/                        # 19,641 AI-generated faces
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fake_0.jpg
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fake_19640.jpg
‚îÇ   ‚îî‚îÄ‚îÄ Real/                        # 19,787 authentic faces
‚îÇ       ‚îú‚îÄ‚îÄ real_0.jpg
‚îÇ       ‚îú‚îÄ‚îÄ ...
‚îÇ       ‚îî‚îÄ‚îÄ real_19786.jpg
‚îÇ
‚îî‚îÄ‚îÄ Test/                            # Test Set (5.73%)
    ‚îú‚îÄ‚îÄ Fake/                        # 5,492 AI-generated faces
    ‚îÇ   ‚îú‚îÄ‚îÄ fake_0.jpg
    ‚îÇ   ‚îú‚îÄ‚îÄ ...
    ‚îÇ   ‚îî‚îÄ‚îÄ fake_5491.jpg
    ‚îî‚îÄ‚îÄ Real/                        # 5,413 authentic faces
        ‚îú‚îÄ‚îÄ real_0.jpg
        ‚îú‚îÄ‚îÄ ...
        ‚îî‚îÄ‚îÄ real_5412.jpg
```

### Dataset Verification Results

From automated validation with `check_dataset.py`:

```json
{
  "root": "dataset",
  "splits": {
    "train": {
      "counts": {
        "Fake": 70001,
        "Real": 70001
      },
      "corrupt": [],
      "sizes": {
        "256x256": 140002
      },
      "samples": [...],
      "sample_grid": "dataset/sample_grid_train.jpg"
    },
    "validation": {
      "counts": {
        "Fake": 19641,
        "Real": 19787
      },
      "corrupt": [],
      "sizes": {
        "256x256": 39428
      },
      "samples": [...],
      "sample_grid": "dataset/sample_grid_validation.jpg"
    },
    "test": {
      "counts": {
        "Fake": 5492,
        "Real": 5413
      },
      "corrupt": [],
      "sizes": {
        "256x256": 10905
      },
      "samples": [...],
      "sample_grid": "dataset/sample_grid_test.jpg"
    }
  }
}
```

### Dataset Characteristics

#### Fake (AI-Generated) Images:

- **Generation Methods**:
  - StyleGAN (NVIDIA)
  - Progressive GAN (ProGAN)
  - Other state-of-the-art GAN architectures
- **Artifacts**:
  - Inconsistent facial features
  - Unnatural hair textures
  - Background artifacts
  - Pupil irregularities
  - Teeth abnormalities
  - Asymmetric facial structures
- **Diversity**: Multiple GAN architectures ensure varied artifact patterns
- **Quality**: High-resolution, realistic-looking faces to challenge detection

#### Real (Authentic) Images:

- **Sources**:
  - FFHQ (Flickr-Faces-HQ) dataset
  - CelebA dataset
  - Other curated face datasets
- **Characteristics**:
  - Natural photographs of real people
  - Diverse demographics (age, ethnicity, gender)
  - Various lighting conditions
  - Different angles and expressions
  - Real-world photography artifacts (blur, noise, compression)
- **Quality**: Professional and amateur photography
- **Diversity**: Wide range of real-world conditions

### Dataset Access

‚ö†Ô∏è **IMPORTANT**: Dataset is **NOT included** in this repository due to size constraints (~5.2 GB).

üì• **Download Instructions**:

1. **Automated Download** (Recommended):

   ```bash
   cd Backend
   pip install kaggle
   # Configure Kaggle API credentials (see Backend/DATASET.md)
   kaggle datasets download -d xhlulu/140k-real-and-fake-faces
   unzip 140k-real-and-fake-faces.zip -d dataset/
   ```

2. **Manual Download**:
   - Visit [Kaggle Dataset Page](https://www.kaggle.com/datasets/xhlulu/140k-real-and-fake-faces)
   - Download ZIP file
   - Extract to `Backend/dataset/`

üìò **Detailed Guide**: See [`Backend/DATASET.md`](Backend/DATASET.md) for:

- Kaggle API setup instructions
- Download verification steps
- Alternative download methods
- Troubleshooting tips

üîç **Dataset Validation**:
After download, verify integrity:

```bash
cd Backend
python check_dataset.py --root dataset --out dataset_summary.json --make_sample_grid
```

## üóÇÔ∏è Project Structure

### Complete Directory Tree

```
F:\Python\ML Project/
‚îú‚îÄ‚îÄ .gitattributes              # Git LFS tracking configuration
‚îú‚îÄ‚îÄ .gitignore                  # Git ignore patterns (Python, Node, etc.)
‚îú‚îÄ‚îÄ README.md                   # üìò This comprehensive documentation
‚îú‚îÄ‚îÄ README_COMPREHENSIVE.md     # üìö Extended documentation (this file)
‚îú‚îÄ‚îÄ SETUP_GUIDE.md              # üìñ Step-by-step installation guide
‚îú‚îÄ‚îÄ QUICK_REFERENCE.md          # ‚ö° Quick command reference
‚îú‚îÄ‚îÄ GIT_LFS_IMPLEMENTATION.md   # üì¶ Git LFS setup and usage guide
‚îÇ
‚îú‚îÄ‚îÄ Backend/                    # üêç Python FastAPI backend service
‚îÇ   ‚îú‚îÄ‚îÄ main.py                 # FastAPI app, endpoints, middleware
‚îÇ   ‚îú‚îÄ‚îÄ service.py              # Model Manager, inference, GradCAM
‚îÇ   ‚îú‚îÄ‚îÄ check_dataset.py        # Dataset validation utility
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt        # Python dependencies
‚îÇ   ‚îú‚îÄ‚îÄ .env                    # Environment variables (not in repo)
‚îÇ   ‚îú‚îÄ‚îÄ .gitignore              # Backend-specific git ignores
‚îÇ   ‚îú‚îÄ‚îÄ DATASET.md              # üì• Dataset download instructions
‚îÇ   ‚îú‚îÄ‚îÄ dataset_summary.json    # Generated dataset statistics
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/                 # üß† Pre-trained model weights (Git LFS)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py         # Python package marker
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ xception.py         # Custom Xception implementation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md           # üì¶ Model files & LFS guide
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ resnet50.pth        # üì¶ ResNet50 weights (98 MB, LFS)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ resnet152v2.pth     # üì¶ ResNet152V2 weights (236 MB, LFS)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inceptionresnetv2.pth # üì¶ InceptionResNetV2 (215 MB, LFS)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ xception.pth        # üì¶ Xception weights (88 MB, LFS)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ efficientnetb4.pth  # üì¶ EfficientNetB4 (75 MB, LFS)
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __pycache__/        # Compiled Python files
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ dataset/                # üìä Training data (NOT in repo)
‚îÇ   ‚îÇ   ‚îÇ                       # Download from Kaggle (see DATASET.md)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Train/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Fake/           # 70,001 fake images (256√ó256)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Real/           # 70,001 real images (256√ó256)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Validation/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Fake/           # 19,641 fake images
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Real/           # 19,787 real images
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Test/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ Fake/           # 5,492 fake images
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ Real/           # 5,413 real images
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ __pycache__/            # Compiled Python files
‚îÇ
‚îî‚îÄ‚îÄ Frontend/                   # ‚öõÔ∏è React + Vite frontend application
    ‚îú‚îÄ‚îÄ index.html              # HTML entry point
    ‚îú‚îÄ‚îÄ package.json            # NPM dependencies & scripts
    ‚îú‚îÄ‚îÄ package-lock.json       # Locked dependency versions
    ‚îú‚îÄ‚îÄ vite.config.js          # Vite build configuration
    ‚îú‚îÄ‚îÄ eslint.config.js        # ESLint code quality rules
    ‚îú‚îÄ‚îÄ .env                    # Environment variables (not in repo)
    ‚îú‚îÄ‚îÄ README.md               # Frontend-specific documentation
    ‚îÇ
    ‚îú‚îÄ‚îÄ public/                 # Static assets served directly
    ‚îÇ   ‚îî‚îÄ‚îÄ (vite.svg, etc.)
    ‚îÇ
    ‚îú‚îÄ‚îÄ src/                    # ‚öõÔ∏è React source code
    ‚îÇ   ‚îú‚îÄ‚îÄ main.jsx            # React app entry point
    ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx             # Root component with routing
    ‚îÇ   ‚îú‚îÄ‚îÄ index.css           # Global styles
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ assets/             # Images, icons, media files
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚îÄ components/         # React components
    ‚îÇ       ‚îÇ
    ‚îÇ       ‚îú‚îÄ‚îÄ HomePage.jsx    # Main page container
    ‚îÇ       ‚îÇ                   # - Theme provider (dark mode)
    ‚îÇ       ‚îÇ                   # - Layout orchestration
    ‚îÇ       ‚îÇ
    ‚îÇ       ‚îú‚îÄ‚îÄ Navbar/
    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ Navbar.jsx  # Navigation bar
    ‚îÇ       ‚îÇ                   # - GitHub repository link
    ‚îÇ       ‚îÇ                   # - Sticky positioning
    ‚îÇ       ‚îÇ
    ‚îÇ       ‚îî‚îÄ‚îÄ ModelSection/   # üéØ Main analysis interface
    ‚îÇ           ‚îú‚îÄ‚îÄ index.js    # Component exports
    ‚îÇ           ‚îú‚îÄ‚îÄ ModelSection.jsx      # Main container
    ‚îÇ           ‚îÇ                         # - Model selector
    ‚îÇ           ‚îÇ                         # - Layout management
    ‚îÇ           ‚îÇ
    ‚îÇ           ‚îú‚îÄ‚îÄ ImageUploadArea.jsx   # Upload interface
    ‚îÇ           ‚îÇ                         # - Drag & drop
    ‚îÇ           ‚îÇ                         # - File picker
    ‚îÇ           ‚îÇ
    ‚îÇ           ‚îú‚îÄ‚îÄ ImageDisplay.jsx      # Original image
    ‚îÇ           ‚îÇ                         # - Preview display
    ‚îÇ           ‚îÇ                         # - Reset button
    ‚îÇ           ‚îÇ
    ‚îÇ           ‚îú‚îÄ‚îÄ HeatmapDisplay.jsx    # Heatmap visualization
    ‚îÇ           ‚îÇ                         # - GradCAM overlay
    ‚îÇ           ‚îÇ                         # - Prediction badge
    ‚îÇ           ‚îÇ                         # - Confidence display
    ‚îÇ           ‚îÇ
    ‚îÇ           ‚îú‚îÄ‚îÄ ExplanationBox.jsx    # AI explanation
    ‚îÇ           ‚îÇ                         # - Color-coded styling
    ‚îÇ           ‚îÇ                         # - Explanation text
    ‚îÇ           ‚îÇ
    ‚îÇ           ‚îú‚îÄ‚îÄ RealImageMessage.jsx  # Success message
    ‚îÇ           ‚îÇ                         # - Real image feedback
    ‚îÇ           ‚îÇ
    ‚îÇ           ‚îú‚îÄ‚îÄ WaitingState.jsx      # Loading state
    ‚îÇ           ‚îÇ                         # - Analysis progress
    ‚îÇ           ‚îÇ
    ‚îÇ           ‚îî‚îÄ‚îÄ hooks/
    ‚îÇ               ‚îî‚îÄ‚îÄ useImageAnalysis.js  # Custom React hook
    ‚îÇ                                        # - State management
    ‚îÇ                                        # - API communication
    ‚îÇ                                        # - File handling
    ‚îÇ
    ‚îú‚îÄ‚îÄ dist/                   # Production build output (generated)
    ‚îî‚îÄ‚îÄ node_modules/           # NPM packages (generated, not in repo)
```

### File Count Summary

| Category                 | Count   | Description                                        |
| ------------------------ | ------- | -------------------------------------------------- |
| **Python Files**         | 4       | main.py, service.py, check_dataset.py, xception.py |
| **JavaScript/JSX Files** | 13      | React components and configuration                 |
| **Model Files**          | 5       | Pre-trained weights (Git LFS)                      |
| **Configuration Files**  | 8       | package.json, vite.config.js, .env, etc.           |
| **Documentation Files**  | 8       | README, guides, references                         |
| **Dataset Images**       | 190,335 | Not in repository, download separately             |

### Key Directories

#### Backend/

- **Purpose**: Python-based API server for model inference
- **Framework**: FastAPI + Uvicorn ASGI
- **Key Files**:
  - `main.py`: API endpoints, routing, CORS middleware
  - `service.py`: Core ML logic, model management, GradCAM
  - `check_dataset.py`: Dataset validation and statistics
- **Dependencies**: Listed in `requirements.txt`

#### Backend/models/

- **Purpose**: Pre-trained deep learning model weights
- **Storage**: Git LFS (Large File Storage)
- **Total Size**: ~712 MB (combined)
- **Tracked Files**: All `.pth` files automatically tracked
- **Note**: Requires Git LFS installation to download

#### Backend/dataset/

- **Purpose**: Training, validation, and test images
- **Status**: NOT included in repository
- **Download**: Required from Kaggle (see DATASET.md)
- **Size**: ~5.2 GB total
- **Structure**: Train/Val/Test splits with Fake/Real classes

#### Frontend/

- **Purpose**: User interface for image analysis
- **Framework**: React 19 + Vite + Material-UI
- **Key Files**:
  - `src/App.jsx`: Router setup
  - `src/components/HomePage.jsx`: Main layout
  - `src/components/ModelSection/ModelSection.jsx`: Analysis UI
  - `src/components/ModelSection/hooks/useImageAnalysis.js`: Logic hook
- **Dependencies**: Listed in `package.json`

#### Frontend/src/components/

- **Purpose**: Modular React components
- **Organization**: Feature-based grouping
- **Patterns**:
  - Component co-location (styles, logic, UI together)
  - Custom hooks for reusable logic
  - PropTypes for type checking
  - Material-UI theming

### Architecture Patterns

1. **Backend (Python)**:

   - **Singleton Pattern**: ModelManager class (single instance)
   - **Factory Pattern**: Model building based on string identifier
   - **Strategy Pattern**: Different preprocessing per model
   - **Dependency Injection**: Device, checkpoints configurable
   - **Error Handling**: Try-catch with logging, HTTP status codes

2. **Frontend (React)**:

   - **Component Composition**: Small, reusable components
   - **Custom Hooks**: useImageAnalysis for complex logic
   - **State Management**: React useState, useCallback, useEffect
   - **Prop Drilling Avoidance**: Hooks centralize state
   - **Responsive Design**: Mobile-first with breakpoints

3. **API Design**:
   - **RESTful**: Resource-based URLs (/models/, /predict/)
   - **Stateless**: Each request independent
   - **JSON**: Standard data format
   - **CORS**: Secure cross-origin access
   - **Versioning Ready**: URL structure allows /v1/, /v2/, etc.

## üõ†Ô∏è Technical Stack

### Backend Technologies

#### Core Framework

| Technology   | Version              | Purpose                         |
| ------------ | -------------------- | ------------------------------- |
| **Python**   | 3.8+                 | Primary programming language    |
| **FastAPI**  | 0.100+               | Modern async web framework      |
| **Uvicorn**  | 0.23+                | ASGI server for FastAPI         |
| **Pydantic** | (FastAPI dependency) | Data validation & serialization |

#### Deep Learning

| Technology      | Version | Purpose                         |
| --------------- | ------- | ------------------------------- |
| **PyTorch**     | 2.0+    | Deep learning framework         |
| **TorchVision** | 0.15+   | Pre-trained models & transforms |
| **timm**        | Latest  | PyTorch Image Models library    |
| **TorchCAM**    | 0.3+    | GradCAM implementation          |

#### Computer Vision & Image Processing

| Technology                 | Version | Purpose                       |
| -------------------------- | ------- | ----------------------------- |
| **OpenCV (opencv-python)** | 4.8+    | Image manipulation & heatmaps |
| **Pillow (PIL)**           | 9.0+    | Image loading & conversion    |
| **NumPy**                  | 1.21+   | Numerical operations          |

#### AI & LLM Integration

| Technology              | Version | Purpose           |
| ----------------------- | ------- | ----------------- |
| **google-generativeai** | 0.3+    | Gemini API client |

#### Data Science & Analysis

| Technology       | Version | Purpose                              |
| ---------------- | ------- | ------------------------------------ |
| **Pandas**       | 2.0+    | Data manipulation                    |
| **scikit-learn** | 1.0+    | ML utilities                         |
| **Matplotlib**   | 3.5+    | Visualization (optional)             |
| **Seaborn**      | 0.11+   | Statistical visualization (optional) |
| **tqdm**         | 4.64+   | Progress bars                        |

#### Utilities

| Technology           | Version | Purpose                         |
| -------------------- | ------- | ------------------------------- |
| **python-dotenv**    | 1.0+    | Environment variable management |
| **python-multipart** | 0.0.6+  | Multipart form data parsing     |

### Frontend Technologies

#### Core Framework

| Technology                   | Version | Purpose                     |
| ---------------------------- | ------- | --------------------------- |
| **React**                    | 19.1.1  | UI library                  |
| **React DOM**                | 19.1.1  | React renderer              |
| **Vite**                     | 7.1.6   | Build tool & dev server     |
| **@vitejs/plugin-react-swc** | 4.0.1   | Fast React refresh with SWC |

#### UI Library

| Technology                      | Version | Purpose           |
| ------------------------------- | ------- | ----------------- |
| **Material-UI (@mui/material)** | 7.3.2   | Component library |
| **@mui/icons-material**         | 7.3.2   | Icon library      |
| **@emotion/react**              | 11.14.0 | CSS-in-JS styling |
| **@emotion/styled**             | 11.14.1 | Styled components |

#### Routing

| Technology           | Version | Purpose             |
| -------------------- | ------- | ------------------- |
| **React Router DOM** | 7.9.1   | Client-side routing |

#### Code Quality & Linting

| Technology                      | Version | Purpose                     |
| ------------------------------- | ------- | --------------------------- |
| **ESLint**                      | 9.35.0  | JavaScript linting          |
| **@eslint/js**                  | 9.35.0  | ESLint core                 |
| **eslint-plugin-react-hooks**   | 5.2.0   | React hooks linting         |
| **eslint-plugin-react-refresh** | 0.4.20  | React refresh linting       |
| **globals**                     | 16.4.0  | Global variables definition |

#### TypeScript (Type Checking)

| Technology           | Version | Purpose                    |
| -------------------- | ------- | -------------------------- |
| **@types/react**     | 19.1.13 | React type definitions     |
| **@types/react-dom** | 19.1.9  | React DOM type definitions |

### Development Tools

#### Version Control

| Tool        | Purpose                       |
| ----------- | ----------------------------- |
| **Git**     | Source code version control   |
| **Git LFS** | Large file storage for models |
| **GitHub**  | Code hosting & collaboration  |

#### Environment Management

| Tool            | Purpose                    |
| --------------- | -------------------------- |
| **Python venv** | Python virtual environment |
| **Node.js**     | JavaScript runtime         |
| **npm**         | Node package manager       |

#### API Testing

| Tool                   | Purpose                       |
| ---------------------- | ----------------------------- |
| **FastAPI Swagger UI** | Interactive API documentation |
| **Redoc**              | Alternative API documentation |
| **curl**               | Command-line API testing      |

### External Services

#### APIs

| Service                     | Purpose                       |
| --------------------------- | ----------------------------- |
| **Google Gemini 2.5 Flash** | Natural language explanations |
| **Kaggle API**              | Dataset download              |

### Infrastructure (Recommended)

#### Compute

| Resource    | Recommended            | Purpose                   |
| ----------- | ---------------------- | ------------------------- |
| **CPU**     | 4+ cores               | Backend processing        |
| **RAM**     | 16 GB+                 | Model loading & inference |
| **GPU**     | NVIDIA CUDA-compatible | Accelerated inference     |
| **VRAM**    | 8 GB+                  | GPU model loading         |
| **Storage** | 20 GB+                 | Models + dataset          |

#### Deployment Options

| Platform              | Use Case                         |
| --------------------- | -------------------------------- |
| **Docker**            | Containerized deployment         |
| **AWS EC2**           | Cloud compute instance           |
| **Google Cloud Run**  | Serverless container deployment  |
| **Azure App Service** | Managed web hosting              |
| **Heroku**            | Simple cloud deployment          |
| **Vercel**            | Frontend hosting (Frontend only) |
| **Netlify**           | Frontend hosting (Frontend only) |

### Browser Compatibility

| Browser     | Minimum Version |
| ----------- | --------------- |
| **Chrome**  | 90+             |
| **Firefox** | 88+             |
| **Safari**  | 14+             |
| **Edge**    | 90+             |

### Operating System Compatibility

| OS          | Status                              |
| ----------- | ----------------------------------- |
| **Windows** | ‚úÖ Tested (10, 11)                  |
| **macOS**   | ‚úÖ Compatible (10.15+)              |
| **Linux**   | ‚úÖ Compatible (Ubuntu 20.04+, etc.) |

---

## üìà Performance Metrics

### Individual Model Performance

Comprehensive training and validation metrics for all models in the ensemble:

| Model                 | Train Accuracy | Train Loss | Val Accuracy | Val Loss   | Generalization Gap |
| --------------------- | -------------- | ---------- | ------------ | ---------- | ------------------ |
| **EfficientNetB4**    | **99.82%**     | 0.0050     | 98.68%       | 0.0787     | 1.14%              |
| **InceptionResNetV2** | **99.62%**     | 0.0093     | **98.88%**   | 0.0441     | **0.74%**          |
| **ResNet152V2**       | **99.72%**     | 0.0085     | 98.87%       | 0.0506     | 0.85%              |
| **Xception**          | 99.41%         | **0.0048** | 98.79%       | 0.0658     | 0.62%              |
| **ResNet50**          | 99.18%         | 0.0206     | 98.57%       | 0.0438     | 0.61%              |
| **Average**           | **99.55%**     | **0.0096** | **98.76%**   | **0.0566** | **0.79%**          |

### Performance Analysis

#### Accuracy Metrics

- **Training Accuracy Range**: 99.18% - 99.82%
  - Highest: EfficientNetB4 (99.82%)
  - Lowest: ResNet50 (99.18%)
  - Spread: 0.64%
- **Validation Accuracy Range**: 98.57% - 98.88%

  - Highest: InceptionResNetV2 (98.88%)
  - Lowest: ResNet50 (98.57%)
  - Spread: 0.31%

- **Average Performance**:
  - Training: 99.55%
  - Validation: 98.76%
  - All models exceed 98.5% validation accuracy

#### Loss Metrics

- **Training Loss Range**: 0.0048 - 0.0206
  - Lowest: Xception (0.0048) - best convergence
  - Highest: ResNet50 (0.0206)
  - Average: 0.0096
- **Validation Loss Range**: 0.0438 - 0.0787
  - Lowest: ResNet50 (0.0438)
  - Highest: EfficientNetB4 (0.0787)
  - Average: 0.0566

#### Overfitting Analysis

- **Generalization Gap**: 0.61% - 1.14%

  - Best: ResNet50 (0.61%) - excellent generalization
  - Worst: EfficientNetB4 (1.14%) - still very good
  - Average: 0.79% - minimal overfitting across all models

- **Overfitting Classification**:
  - **Excellent** (<0.75%): ResNet50, Xception
  - **Very Good** (0.75%-1.0%): InceptionResNetV2, ResNet152V2
  - **Good** (1.0%-1.5%): EfficientNetB4

### Ensemble Performance Advantages

The ensemble approach combines these individual models for superior performance:

1. **Diversity**: Different architectures capture different feature patterns

   - ResNet: Deep residual connections
   - Inception: Multi-scale feature extraction
   - Xception: Depthwise separable convolutions
   - EfficientNet: Compound scaling

2. **Error Reduction**: Individual model biases cancel out through averaging

   - Expected ensemble accuracy: >99.0%
   - Reduced variance in predictions
   - More robust to edge cases

3. **Confidence Calibration**: Ensemble probabilities are better calibrated

   - Weighted averaging based on per-model confidence
   - More reliable uncertainty estimation
   - Better decision thresholds

4. **Complementary Strengths**:
   - InceptionResNetV2: Best validation accuracy (98.88%)
   - EfficientNetB4: Highest training accuracy (99.82%)
   - Xception: Lowest training loss (0.0048)
   - ResNet50: Best generalization (0.61% gap)
   - ResNet152V2: Balanced performance (99.72% train, 98.87% val)

### Inference Performance

| Metric                            | GPU (CUDA) | CPU     |
| --------------------------------- | ---------- | ------- |
| **Single Model Inference**        | ~0.4-1.0s  | ~2-4s   |
| **Ensemble Inference (5 models)** | ~2-5s      | ~10-20s |
| **GradCAM Generation**            | ~0.2-0.5s  | ~1-2s   |
| **Total Processing Time**         | ~2.5-6s    | ~11-22s |
| **Throughput (images/minute)**    | ~10-24     | ~3-5    |

**Note**: Times vary based on:

- Input image size
- Hardware specifications
- Model selection (ensemble vs individual)
- GradCAM computation enabled/disabled

### Model Comparison Insights

**Best for Speed**: ResNet50

- Smallest model (25.6M parameters)
- Fastest inference time
- Good accuracy (98.57% validation)

**Best for Accuracy**: InceptionResNetV2

- Highest validation accuracy (98.88%)
- Low validation loss (0.0441)
- Excellent generalization (0.74% gap)

**Best for Generalization**: ResNet50 & Xception

- Minimal overfitting (<0.65% gap)
- Stable performance across train/val
- Reliable predictions

**Most Powerful**: ResNet152V2

- Largest model (60.2M parameters)
- Excellent all-around performance (99.72% train, 98.87% val)
- Strong feature extraction

**Most Efficient**: EfficientNetB4

- Best parameter efficiency (19.3M params)
- Highest training accuracy (99.82%)
- Compound scaling advantages

### Dataset Performance Statistics

**Training Set** (140,002 images):

- Average accuracy across all models: **99.55%**
- Images correctly classified: ~139,372
- Images misclassified: ~630

**Validation Set** (39,428 images):

- Average accuracy across all models: **98.76%**
- Images correctly classified: ~38,939
- Images misclassified: ~489

**Expected Test Set Performance** (10,905 images):

- Estimated accuracy: **98.5% - 99.0%**
- Expected correct classifications: ~10,740-10,796
- Expected misclassifications: ~109-165

### Performance Optimization

Techniques used to achieve these results:

1. **Data Augmentation**: Enhanced training diversity
2. **Transfer Learning**: Leveraged ImageNet pre-training
3. **Fine-tuning**: Task-specific adaptation
4. **Regularization**: Dropout, weight decay
5. **Learning Rate Scheduling**: Optimal convergence
6. **Early Stopping**: Prevented overfitting
7. **Ensemble Averaging**: Combined model strengths

---

**Continue to [Installation](#-installation) ‚Üí**
