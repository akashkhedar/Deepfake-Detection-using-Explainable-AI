# Deepfake Detection using Explainable AI

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.8%2B-blue)
![React](https://img.shields.io/badge/react-19.1.1-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.100%2B-green)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange)
![Material--UI](https://img.shields.io/badge/Material--UI-7.3.2-blue)

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [System Architecture](#-system-architecture)
- [Dataset Information](#-dataset-information)
- [Project Structure](#-project-structure)
- [Technical Stack](#-technical-stack)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Usage](#-usage)
- [API Documentation](#-api-documentation)
- [Frontend Components](#-frontend-components)
- [Backend Architecture](#-backend-architecture)
- [Model Details](#-model-details)
- [Explainability Features](#-explainability-features)
- [Performance Metrics](#-performance-metrics)
- [Utilities & Tools](#-utilities--tools)
- [Testing & Validation](#-testing--validation)
- [Deployment](#-deployment)
- [Troubleshooting](#-troubleshooting)
- [Contributing](#-contributing)
- [License](#-license)
- [Acknowledgments](#-acknowledgments)
- [Future Enhancements](#-future-enhancements)
- [Contact](#-contact)

## ğŸ¯ Overview

An **enterprise-grade deepfake detection system** powered by an ensemble of state-of-the-art deep learning models with comprehensive explainable AI capabilities. This project combines multiple CNN architectures with GradCAM visualization and AI-powered natural language explanations to detect manipulated images with high accuracy, transparency, and user trust.

**Key Highlights:**

- ğŸ¤– **5-Model Ensemble Architecture**: Combines ResNet50, ResNet152V2, InceptionResNetV2, Xception, and EfficientNetB4
- ğŸ” **Advanced Explainable AI**: GradCAM heatmaps + Google Gemini 2.5 Flash-powered natural language explanations
- ğŸŒ **Modern Web Interface**: React 19 + Material-UI with responsive design and real-time analysis
- âš¡ **High Performance Backend**: FastAPI with async support and GPU acceleration
- ğŸ“Š **Massive Dataset**: 190,335+ verified images (real and AI-generated)
- ğŸ¨ **Interactive Visualizations**: Real-time heatmap overlays showing model attention regions
- ğŸ“¦ **Production Ready**: Docker support, comprehensive logging, error handling, and monitoring
- ğŸ”’ **Secure & Scalable**: CORS configuration, environment-based secrets, scalable architecture

## ğŸŒŸ Features

### Core Capabilities

#### 1. **Multi-Model Ensemble Architecture**

- **5 Powerful CNN Models** working in concert:

  - **ResNet50** (25.6M parameters) - Residual learning for deep networks, 224Ã—224 input
  - **ResNet152V2** (60.2M parameters) - Deeper residual architecture, 224Ã—224 input
  - **InceptionResNetV2** (55.8M parameters) - Multi-scale feature extraction, 299Ã—299 input
  - **Xception** (22.9M parameters) - Depthwise separable convolutions, 299Ã—299 input
  - **EfficientNetB4** (19.3M parameters) - Compound scaling optimization, 380Ã—380 input

- **Model Performance Metrics**:

| Model                 | Train Accuracy | Train Loss | Val Accuracy | Val Loss |
| --------------------- | -------------- | ---------- | ------------ | -------- |
| **EfficientNetB4**    | **99.82%**     | 0.0050     | 98.68%       | 0.0787   |
| **InceptionResNetV2** | **99.62%**     | 0.0093     | **98.88%**   | 0.0441   |
| **ResNet152V2**       | **99.72%**     | 0.0085     | 98.87%       | 0.0506   |
| **Xception**          | 99.41%         | 0.0048     | 98.79%       | 0.0658   |
| **ResNet50**          | 99.18%         | 0.0206     | 98.57%       | 0.0438   |
| **Average**           | **99.55%**     | 0.0096     | **98.76%**   | 0.0566   |

- All models achieve >98.5% validation accuracy
- Average generalization gap: 0.79% (minimal overfitting)
- Best validation performer: InceptionResNetV2 (98.88%)
- Highest training accuracy: EfficientNetB4 (99.82%)
- Lowest training loss: Xception (0.0048)

- **Ensemble Prediction**: Weighted averaging of softmax probabilities across all models
- **Individual Model Selection**: Test specific models independently or compare results
- **Robust Decision Making**: Reduces individual model biases through diversity
- **Dynamic Model Loading**: Selective model loading based on configuration

#### 2. **Explainable AI (XAI) Framework**

- **GradCAM Heatmap Visualization**:
  - Gradient-weighted Class Activation Mapping for visual explanations
  - Shows which image regions influenced the model's decision
  - Color-coded attention maps (red/yellow = high attention, blue = low attention)
  - Weighted fusion of heatmaps from all ensemble models
  - Real-time overlay generation with 40% heatmap + 60% original image composition
  - Model-specific target layers for optimal activation extraction
- **AI-Generated Natural Language Explanations**:
  - Powered by Google Gemini 2.5 Flash multimodal API
  - Context-aware explanations based on prediction label and heatmap
  - Human-readable justifications for each decision in 2-3 sentences
  - Automatic fallback to generic explanations if API unavailable
  - Vision-language integration for deeper understanding
- **Per-Model Confidence Breakdown**:
  - Individual confidence scores for each model
  - Ensemble confidence aggregation
  - Real vs Fake probability distribution
  - Complete transparency in decision-making process
  - JSON-formatted detailed metrics

#### 3. **Modern Web Interface**

- **Responsive React-based UI**:
  - Mobile-first design with adaptive layouts for all screen sizes
  - Dark theme optimized for visual comfort and professional appearance
  - Material-UI 7.3.2 components for consistent, polished interface
  - Real-time state management with React hooks (useImageAnalysis)
  - Smooth animations and transitions for better UX
- **Interactive Features**:
  - Drag-and-drop image upload with visual feedback
  - File browser integration with image format validation
  - Live analysis progress indicators with loading states
  - Instant result visualization without page reloads
  - Model selector dropdown (Ensemble + 5 individual models)
  - Reset functionality to analyze multiple images
- **Rich Visual Feedback**:
  - Original image display with responsive borders
  - Side-by-side heatmap comparison layout
  - Color-coded prediction badges (Green = Real, Red = Fake, Orange = Error)
  - Confidence percentage displays with precision
  - Detailed explanation cards with contextual styling
  - Smooth state transitions and animations

#### 4. **Production-Ready Backend**

- **FastAPI Framework**:
  - Async/await request handling for high concurrent performance
  - Auto-generated OpenAPI documentation (Swagger UI at /docs)
  - Type hints and automatic data validation with Pydantic
  - RESTful API design following best practices
  - Built-in request/response schemas
- **Advanced Features**:
  - CORS middleware for secure cross-origin requests
  - GPU/CPU automatic device detection with fallback
  - Batch model loading on application startup
  - Comprehensive error handling with proper HTTP status codes
  - Structured logging with log levels (INFO, WARNING, ERROR)
  - Health check and status monitoring endpoints
  - Model availability checking before inference
- **Performance Optimizations**:
  - Model caching in memory (singleton pattern)
  - Efficient image preprocessing pipelines with transforms
  - Parallel GradCAM computation across models
  - Optimized tensor operations with PyTorch JIT (where applicable)
  - Minimal memory footprint with cleanup
  - Fast multipart/form-data parsing

#### 5. **Dataset Management**

- **Comprehensive Validation Tools** (`check_dataset.py`):
  - Automatic image corruption detection with PIL verification
  - Image integrity verification (file header checks)
  - Size distribution analysis across splits
  - Class balance statistics and imbalance detection
  - Sample grid generation for visual inspection
  - JSON summary export for documentation
  - Progress bars with tqdm for large datasets
- **Flexible Data Organization**:
  - Train/Validation/Test split structure (73.5% / 20.7% / 5.7%)
  - Real/Fake binary classification folders
  - Standardized 256Ã—256 resolution across all images
  - Zero corrupted images verified (100% integrity)
  - Hierarchical directory structure for scalability

#### 6. **Developer Experience**

- **Git LFS Integration**:
  - Efficient handling of large model files (~1.66 GB total)
  - Automatic tracking for `.pth`, `.pt`, `.h5`, `.onnx`, `.pkl` files
  - Pointer files in repo, actual files in LFS storage
  - Simple clone-and-go workflow
- **Comprehensive Documentation**:
  - README.md with complete project overview
  - SETUP_GUIDE.md with step-by-step installation
  - QUICK_REFERENCE.md for common commands
  - Backend/DATASET.md for dataset download
  - Backend/models/README.md for model files
  - GIT_LFS_IMPLEMENTATION.md for LFS details
  - Inline code comments and docstrings
- **Environment Configuration**:
  - `.env` support for secrets and configuration
  - Environment variable validation
  - Separate configs for dev/prod environments
  - Configurable model loading (all or selective)
- **Logging & Debugging**:
  - Detailed logs for monitoring and debugging
  - Configurable log levels
  - Request/response logging
  - Error stack traces
  - Performance metrics tracking
- **Code Quality**:
  - Type hints throughout codebase
  - Modular architecture with clear separation
  - Single Responsibility Principle
  - DRY (Don't Repeat Yourself) practices
  - Consistent naming conventions

## ğŸ›ï¸ System Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Frontend Layer                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  React 19 + Vite + Material-UI                           â”‚  â”‚
â”‚  â”‚  Port: 5173 (Development) / 4173 (Preview)               â”‚  â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚  â”‚
â”‚  â”‚  â€¢ App.jsx (Router + Root Component)                     â”‚  â”‚
â”‚  â”‚  â€¢ HomePage.jsx (Theme Provider + Dark Mode)             â”‚  â”‚
â”‚  â”‚  â€¢ Navbar.jsx (GitHub Navigation)                        â”‚  â”‚
â”‚  â”‚  â€¢ ModelSection.jsx (Main Analysis Interface)            â”‚  â”‚
â”‚  â”‚  â€¢ useImageAnalysis.js (Custom Hook - State Management)  â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  Sub-Components:                                         â”‚  â”‚
â”‚  â”‚  â€¢ ImageUploadArea.jsx (Drag & Drop + File Picker)       â”‚  â”‚
â”‚  â”‚  â€¢ ImageDisplay.jsx (Original Image Display)             â”‚  â”‚
â”‚  â”‚  â€¢ HeatmapDisplay.jsx (GradCAM Visualization)            â”‚  â”‚
â”‚  â”‚  â€¢ ExplanationBox.jsx (AI Explanation Rendering)         â”‚  â”‚
â”‚  â”‚  â€¢ RealImageMessage.jsx (Success State Display)          â”‚  â”‚
â”‚  â”‚  â€¢ WaitingState.jsx (Loading Indicators)                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ HTTP/REST API (JSON + Base64)
                            â”‚ CORS-enabled, async requests
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Backend Layer                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  FastAPI + Uvicorn ASGI Server                           â”‚  â”‚
â”‚  â”‚  Port: 8000 (Configurable)                               â”‚  â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚  â”‚
â”‚  â”‚  â€¢ main.py (API Endpoints, Routing, Middleware)          â”‚  â”‚
â”‚  â”‚    - GET  /            (Health Check)                    â”‚  â”‚
â”‚  â”‚    - GET  /models/     (List Loaded Models)              â”‚  â”‚
â”‚  â”‚    - GET  /status/     (System Status & Device Info)     â”‚  â”‚
â”‚  â”‚    - POST /predict/    (Image Analysis Endpoint)         â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  â€¢ service.py (Core Logic)                               â”‚  â”‚
â”‚  â”‚    - ModelManager Class (Singleton)                      â”‚  â”‚
â”‚  â”‚    - Model Loading & Checkpoint Management               â”‚  â”‚
â”‚  â”‚    - Inference Orchestration                             â”‚  â”‚
â”‚  â”‚    - GradCAM Generation                                  â”‚  â”‚
â”‚  â”‚    - Gemini API Integration                              â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  â€¢ CORS Middleware (Cross-Origin Security)               â”‚  â”‚
â”‚  â”‚  â€¢ Error Handlers & Exception Logging                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Deep Learning Layer                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  PyTorch 2.0+ with CUDA/CPU Support                      â”‚  â”‚
â”‚  â”‚  Device: Auto-detect (CUDA if available, else CPU)       â”‚  â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚ ResNet50   â”‚ ResNet152V2  â”‚ Inception   â”‚ Xception â”‚ â”‚  â”‚
â”‚  â”‚  â”‚            â”‚              â”‚ ResNetV2    â”‚          â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ Input:     â”‚ Input:       â”‚ Input:      â”‚ Input:   â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ 224Ã—224    â”‚ 224Ã—224      â”‚ 299Ã—299     â”‚ 299Ã—299  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚            â”‚              â”‚             â”‚          â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ Size:      â”‚ Size:        â”‚ Size:       â”‚ Size:    â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ ~98 MB     â”‚ ~236 MB      â”‚ ~215 MB     â”‚ ~88 MB   â”‚ â”‚  â”‚
â”‚  â”‚  â”‚            â”‚              â”‚             â”‚          â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ Params:    â”‚ Params:      â”‚ Params:     â”‚ Params:  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ 25.6M      â”‚ 60.2M        â”‚ 55.8M       â”‚ 22.9M    â”‚ â”‚  â”‚
â”‚  â”‚  â”‚            â”‚              â”‚             â”‚          â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ Target:    â”‚ Target:      â”‚ Target:     â”‚ Target:  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ layer4[-1] â”‚ layer4[-1]   â”‚ Mixed_7c    â”‚ block4   â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ .conv2     â”‚ .conv2       â”‚ (conv2d_7b) â”‚          â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚ EfficientNetB4                                       â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ Input: 380Ã—380 | Size: ~75 MB | Params: 19.3M       â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ Target: blocks[-1][-1].conv_pwl                      â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  Preprocessing Pipeline:                                 â”‚  â”‚
â”‚  â”‚  â€¢ Resize to model-specific dimensions                   â”‚  â”‚
â”‚  â”‚  â€¢ Convert to Tensor                                     â”‚  â”‚
â”‚  â”‚  â€¢ Normalize with ImageNet stats                         â”‚  â”‚
â”‚  â”‚    Mean: [0.485, 0.456, 0.406]                           â”‚  â”‚
â”‚  â”‚    Std:  [0.229, 0.224, 0.225]                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Explainability Layer                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  TorchCAM (GradCAM Implementation)                       â”‚  â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚  â”‚
â”‚  â”‚  â€¢ Target layer extraction per model architecture        â”‚  â”‚
â”‚  â”‚  â€¢ Gradient computation with backward pass               â”‚  â”‚
â”‚  â”‚  â€¢ Activation map generation (class-specific)            â”‚  â”‚
â”‚  â”‚  â€¢ CAM normalization and resizing to original size       â”‚  â”‚
â”‚  â”‚  â€¢ Weighted heatmap fusion (confidence-based weights)    â”‚  â”‚
â”‚  â”‚  â€¢ Overlay composition with OpenCV:                      â”‚  â”‚
â”‚  â”‚    - Apply JET colormap to normalized CAM                â”‚  â”‚
â”‚  â”‚    - Blend: 40% heatmap + 60% original image             â”‚  â”‚
â”‚  â”‚    - Encode to base64 PNG for transmission               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Google Gemini 2.5 Flash API                             â”‚  â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚  â”‚
â”‚  â”‚  â€¢ Natural language explanation generation               â”‚  â”‚
â”‚  â”‚  â€¢ Context-aware reasoning based on prediction label     â”‚  â”‚
â”‚  â”‚  â€¢ Vision-language multimodal integration                â”‚  â”‚
â”‚  â”‚  â€¢ Input: Prediction label + Heatmap overlay (base64)    â”‚  â”‚
â”‚  â”‚  â€¢ Output: 2-3 sentence human-readable explanation       â”‚  â”‚
â”‚  â”‚  â€¢ Fallback: Generic explanation if API fails            â”‚  â”‚
â”‚  â”‚  â€¢ Rate limiting & error handling                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Action     â”‚
â”‚ Upload Image    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend Processing          â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚ 1. File validation           â”‚
â”‚    â€¢ Type check (image/*)    â”‚
â”‚    â€¢ Size limit check        â”‚
â”‚ 2. FileReader API            â”‚
â”‚    â€¢ Convert to base64       â”‚
â”‚    â€¢ Generate preview URL    â”‚
â”‚ 3. State Management          â”‚
â”‚    â€¢ Update selectedImage    â”‚
â”‚    â€¢ Set isAnalyzing = true  â”‚
â”‚    â€¢ Clear previous results  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HTTP POST Request            â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚ URL: /predict/               â”‚
â”‚ Query: ?model=<name>         â”‚
â”‚        (optional)            â”‚
â”‚ Body: multipart/form-data    â”‚
â”‚   file: <binary image data>  â”‚
â”‚ Headers:                     â”‚
â”‚   Content-Type:              â”‚
â”‚     multipart/form-data      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backend API Endpoint                 â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚ @app.post("/predict/")               â”‚
â”‚ 1. Receive UploadFile                â”‚
â”‚ 2. Read file bytes: await file.read()â”‚
â”‚ 3. Open with PIL: Image.open()       â”‚
â”‚ 4. Convert to RGB: .convert("RGB")   â”‚
â”‚ 5. Extract model param from query    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model Manager Dispatcher              â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚ Route based on model parameter:       â”‚
â”‚                                       â”‚
â”‚ if model specified:                   â”‚
â”‚   â†’ predict_single(model, image)      â”‚
â”‚ else:                                 â”‚
â”‚   â†’ predict_ensemble(image)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚                â”‚
        â–¼                 â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Single Model  â”‚  â”‚ Ensemble     â”‚  â”‚ Ensemble     â”‚
â”‚Prediction    â”‚  â”‚ Model 1      â”‚  â”‚ Model 2-5    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚                â”‚
       â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                          â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ For Each Model (Parallel in Ensemble):  â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚ 1. Get model-specific preprocessor      â”‚
â”‚    â€¢ Resize to input dimensions          â”‚
â”‚    â€¢ ToTensor transformation             â”‚
â”‚    â€¢ Normalize with ImageNet stats       â”‚
â”‚                                          â”‚
â”‚ 2. Prepare input tensor                 â”‚
â”‚    â€¢ Add batch dimension: unsqueeze(0)   â”‚
â”‚    â€¢ Move to device: .to(device)         â”‚
â”‚    â€¢ Enable gradients: requires_grad_()  â”‚
â”‚                                          â”‚
â”‚ 3. Forward pass through model            â”‚
â”‚    â€¢ output = model(input_tensor)        â”‚
â”‚                                          â”‚
â”‚ 4. Compute probabilities                â”‚
â”‚    â€¢ For Xception: direct sigmoid output â”‚
â”‚    â€¢ For others: F.softmax(output, dim=1)â”‚
â”‚                                          â”‚
â”‚ 5. Handle class inversion                â”‚
â”‚    â€¢ InceptionResNet & EfficientNet:     â”‚
â”‚      Index 0 = Real, Index 1 = Fake      â”‚
â”‚    â€¢ Others:                             â”‚
â”‚      Index 0 = Fake, Index 1 = Real      â”‚
â”‚    â€¢ Unify to [Fake, Real] format        â”‚
â”‚                                          â”‚
â”‚ 6. Determine prediction                 â”‚
â”‚    â€¢ pred_idx = argmax(probabilities)    â”‚
â”‚    â€¢ label = "Real" if pred_idx==1       â”‚
â”‚              else "Fake"                 â”‚
â”‚                                          â”‚
â”‚ 7. Extract GradCAM                       â”‚
â”‚    â€¢ cam_extractor = GradCAM(model)      â”‚
â”‚    â€¢ Determine target class index        â”‚
â”‚      (handle model-specific inversions)  â”‚
â”‚    â€¢ cam = cam_extractor(class_idx, out) â”‚
â”‚    â€¢ Normalize CAM to [0, 1]             â”‚
â”‚    â€¢ Resize to original image size       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Aggregate Results (Ensemble Only)        â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚ 1. Collect all unified probabilities     â”‚
â”‚    â€¢ Stack: [[Fake, Real], ...]          â”‚
â”‚                                          â”‚
â”‚ 2. Average probabilities                 â”‚
â”‚    â€¢ ensemble_probs = mean(all_probs)    â”‚
â”‚                                          â”‚
â”‚ 3. Determine ensemble prediction         â”‚
â”‚    â€¢ pred_idx = argmax(ensemble_probs)   â”‚
â”‚    â€¢ label = "Real" if pred_idx==1       â”‚
â”‚              else "Fake"                 â”‚
â”‚                                          â”‚
â”‚ 4. Fuse GradCAMs                         â”‚
â”‚    â€¢ weights = confidence per model      â”‚
â”‚    â€¢ Normalize weights: sum = 1.0        â”‚
â”‚    â€¢ Weighted sum of CAMs                â”‚
â”‚    â€¢ ensemble_cam = Î£(weight_i * cam_i)  â”‚
â”‚    â€¢ Normalize final CAM                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Generate Heatmap Overlay                 â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚ 1. Denormalize input image               â”‚
â”‚    â€¢ Reverse ImageNet normalization      â”‚
â”‚    â€¢ Clip to [0, 1] range                â”‚
â”‚    â€¢ Resize to original dimensions       â”‚
â”‚                                          â”‚
â”‚ 2. Apply colormap to CAM                 â”‚
â”‚    â€¢ Convert CAM to uint8: cam * 255     â”‚
â”‚    â€¢ Apply JET colormap (OpenCV)         â”‚
â”‚    â€¢ Convert BGR to RGB                  â”‚
â”‚                                          â”‚
â”‚ 3. Create overlay                        â”‚
â”‚    â€¢ Blend: 0.4 * heatmap + 0.6 * image  â”‚
â”‚    â€¢ Clip to [0, 1]                      â”‚
â”‚    â€¢ Convert to uint8: * 255             â”‚
â”‚                                          â”‚
â”‚ 4. Encode to base64                      â”‚
â”‚    â€¢ imencode to PNG format              â”‚
â”‚    â€¢ base64 encode buffer                â”‚
â”‚    â€¢ Decode to UTF-8 string              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Generate AI Explanation (if Fake)        â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚ if prediction == "Fake":                 â”‚
â”‚   1. Check Gemini API availability       â”‚
â”‚   2. Prepare prompt:                     â”‚
â”‚      "Model predicted {label}.           â”‚
â”‚       Heatmap shows attention regions.   â”‚
â”‚       Explain why in 2-3 sentences."     â”‚
â”‚   3. Call Gemini API:                    â”‚
â”‚      â€¢ Model: gemini-2.5-flash           â”‚
â”‚      â€¢ Input: [prompt, heatmap_base64]   â”‚
â”‚   4. Extract explanation text            â”‚
â”‚   5. Fallback on error:                  â”‚
â”‚      Generic message                     â”‚
â”‚ else:                                    â”‚
â”‚   Generic "Real" explanation             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Construct JSON Response                  â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚ Single Model Response:                   â”‚
â”‚ {                                        â”‚
â”‚   "model": "resnet50",                   â”‚
â”‚   "prediction": "Fake",                  â”‚
â”‚   "confidence": 0.9532,                  â”‚
â”‚   "probabilities": {                     â”‚
â”‚     "real": 0.0468,                      â”‚
â”‚     "fake": 0.9532                       â”‚
â”‚   },                                     â”‚
â”‚   "heatmap": "data:image/png;base64,...",â”‚
â”‚   "explanation": "The model detected..." â”‚
â”‚ }                                        â”‚
â”‚                                          â”‚
â”‚ Ensemble Response:                       â”‚
â”‚ {                                        â”‚
â”‚   "ensemble_prediction": "Fake",         â”‚
â”‚   "ensemble_confidence": 0.9621,         â”‚
â”‚   "ensemble_probabilities": {            â”‚
â”‚     "real": 0.0379,                      â”‚
â”‚     "fake": 0.9621                       â”‚
â”‚   },                                     â”‚
â”‚   "per_model_confidences": {             â”‚
â”‚     "resnet50": {"real": 0.05, ...},     â”‚
â”‚     "resnet152": {"real": 0.03, ...},    â”‚
â”‚     ...                                  â”‚
â”‚   },                                     â”‚
â”‚   "heatmap": "data:image/png;base64,...",â”‚
â”‚   "explanation": "The ensemble..."       â”‚
â”‚ }                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend State Update                    â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚ 1. Parse JSON response                   â”‚
â”‚ 2. Extract data:                         â”‚
â”‚    â€¢ prediction = response.prediction    â”‚
â”‚      or response.ensemble_prediction     â”‚
â”‚    â€¢ confidence = response.confidence    â”‚
â”‚      or response.ensemble_confidence     â”‚
â”‚    â€¢ heatmap = response.heatmap          â”‚
â”‚    â€¢ explanation = response.explanation  â”‚
â”‚ 3. Update React state:                   â”‚
â”‚    â€¢ setPrediction(prediction)           â”‚
â”‚    â€¢ setConfidence(confidence)           â”‚
â”‚    â€¢ setHeatmapUrl(heatmap)              â”‚
â”‚    â€¢ setExplanation(explanation)         â”‚
â”‚    â€¢ setIsAnalyzing(false)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ UI Rendering                             â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚ â€¢ ImageDisplay: Show original image      â”‚
â”‚ â€¢ HeatmapDisplay: Render heatmap overlay â”‚
â”‚   - Color-coded badge (Red/Green)        â”‚
â”‚   - Confidence percentage                â”‚
â”‚ â€¢ ExplanationBox: Display AI explanation â”‚
â”‚   - Contextual styling based on result   â”‚
â”‚ â€¢ Animation: Smooth transitions          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Dataset Information

### Dataset Overview

The models are trained on a comprehensive, large-scale dataset of real and AI-generated face images sourced from Kaggle, specifically curated for deepfake detection research.

**Dataset Source**: [140k Real and Fake Faces - Kaggle](https://www.kaggle.com/datasets/xhlulu/140k-real-and-fake-faces)

### Comprehensive Dataset Statistics

| Split      | Fake Images | Real Images | Total       | Percentage | Avg per Class |
| ---------- | ----------- | ----------- | ----------- | ---------- | ------------- |
| Training   | 70,001      | 70,001      | 140,002     | 73.54%     | 70,001        |
| Validation | 19,641      | 19,787      | 39,428      | 20.71%     | 19,714        |
| Test       | 5,492       | 5,413       | 10,905      | 5.73%      | 5,452.5       |
| **Total**  | **95,134**  | **95,201**  | **190,335** | **100%**   | **95,167.5**  |

**Class Balance**: 99.97% balanced (95,134 fake vs 95,201 real = 49.98% vs 50.02%)

### Technical Specifications

| Specification        | Value             | Description                    |
| -------------------- | ----------------- | ------------------------------ |
| **Image Resolution** | 256Ã—256 pixels    | Standardized across all images |
| **Color Space**      | RGB (3 channels)  | Full color information         |
| **Bit Depth**        | 8-bit per channel | Standard image encoding        |
| **File Format**      | JPEG              | Compressed format              |
| **Compression**      | Variable quality  | Optimized file size            |
| **Total Storage**    | ~5.2 GB           | Complete dataset size          |
| **Image Integrity**  | 100% verified     | Zero corrupted files           |
| **Missing Files**    | 0                 | Complete dataset               |
| **Duplicate Files**  | 0                 | All unique images              |

### Dataset Structure

```
dataset/
â”œâ”€â”€ Train/                           # Training Set (73.54%)
â”‚   â”œâ”€â”€ Fake/                        # 70,001 AI-generated faces
â”‚   â”‚   â”œâ”€â”€ fake_0.jpg               # StyleGAN generated
â”‚   â”‚   â”œâ”€â”€ fake_1.jpg               # ProGAN generated
â”‚   â”‚   â”œâ”€â”€ fake_2.jpg               # Various GAN architectures
â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”‚   â””â”€â”€ fake_70000.jpg
â”‚   â””â”€â”€ Real/                        # 70,001 authentic faces
â”‚       â”œâ”€â”€ real_0.jpg               # FFHQ dataset
â”‚       â”œâ”€â”€ real_1.jpg               # CelebA dataset
â”‚       â”œâ”€â”€ real_2.jpg               # Various sources
â”‚       â”œâ”€â”€ ...
â”‚       â””â”€â”€ real_70000.jpg
â”‚
â”œâ”€â”€ Validation/                      # Validation Set (20.71%)
â”‚   â”œâ”€â”€ Fake/                        # 19,641 AI-generated faces
â”‚   â”‚   â”œâ”€â”€ fake_0.jpg
â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”‚   â””â”€â”€ fake_19640.jpg
â”‚   â””â”€â”€ Real/                        # 19,787 authentic faces
â”‚       â”œâ”€â”€ real_0.jpg
â”‚       â”œâ”€â”€ ...
â”‚       â””â”€â”€ real_19786.jpg
â”‚
â””â”€â”€ Test/                            # Test Set (5.73%)
    â”œâ”€â”€ Fake/                        # 5,492 AI-generated faces
    â”‚   â”œâ”€â”€ fake_0.jpg
    â”‚   â”œâ”€â”€ ...
    â”‚   â””â”€â”€ fake_5491.jpg
    â””â”€â”€ Real/                        # 5,413 authentic faces
        â”œâ”€â”€ real_0.jpg
        â”œâ”€â”€ ...
        â””â”€â”€ real_5412.jpg
```

### Dataset Verification Results

From automated validation with `check_dataset.py`:

```json
{
  "root": "dataset",
  "splits": {
    "train": {
      "counts": {
        "Fake": 70001,
        "Real": 70001
      },
      "corrupt": [],
      "sizes": {
        "256x256": 140002
      },
      "samples": [...],
      "sample_grid": "dataset/sample_grid_train.jpg"
    },
    "validation": {
      "counts": {
        "Fake": 19641,
        "Real": 19787
      },
      "corrupt": [],
      "sizes": {
        "256x256": 39428
      },
      "samples": [...],
      "sample_grid": "dataset/sample_grid_validation.jpg"
    },
    "test": {
      "counts": {
        "Fake": 5492,
        "Real": 5413
      },
      "corrupt": [],
      "sizes": {
        "256x256": 10905
      },
      "samples": [...],
      "sample_grid": "dataset/sample_grid_test.jpg"
    }
  }
}
```

### Dataset Characteristics

#### Fake (AI-Generated) Images:

- **Generation Methods**:
  - StyleGAN (NVIDIA)
  - Progressive GAN (ProGAN)
  - Other state-of-the-art GAN architectures
- **Artifacts**:
  - Inconsistent facial features
  - Unnatural hair textures
  - Background artifacts
  - Pupil irregularities
  - Teeth abnormalities
  - Asymmetric facial structures
- **Diversity**: Multiple GAN architectures ensure varied artifact patterns
- **Quality**: High-resolution, realistic-looking faces to challenge detection

#### Real (Authentic) Images:

- **Sources**:
  - FFHQ (Flickr-Faces-HQ) dataset
  - CelebA dataset
  - Other curated face datasets
- **Characteristics**:
  - Natural photographs of real people
  - Diverse demographics (age, ethnicity, gender)
  - Various lighting conditions
  - Different angles and expressions
  - Real-world photography artifacts (blur, noise, compression)
- **Quality**: Professional and amateur photography
- **Diversity**: Wide range of real-world conditions

### Dataset Access

âš ï¸ **IMPORTANT**: Dataset is **NOT included** in this repository due to size constraints (~5.2 GB).

ğŸ“¥ **Download Instructions**:

1. **Automated Download** (Recommended):

   ```bash
   cd Backend
   pip install kaggle
   # Configure Kaggle API credentials (see Backend/DATASET.md)
   kaggle datasets download -d xhlulu/140k-real-and-fake-faces
   unzip 140k-real-and-fake-faces.zip -d dataset/
   ```

2. **Manual Download**:
   - Visit [Kaggle Dataset Page](https://www.kaggle.com/datasets/xhlulu/140k-real-and-fake-faces)
   - Download ZIP file
   - Extract to `Backend/dataset/`

ğŸ“˜ **Detailed Guide**: See [`Backend/DATASET.md`](Backend/DATASET.md) for:

- Kaggle API setup instructions
- Download verification steps
- Alternative download methods
- Troubleshooting tips

ğŸ” **Dataset Validation**:
After download, verify integrity:

```bash
cd Backend
python check_dataset.py --root dataset --out dataset_summary.json --make_sample_grid
```

## ğŸ—‚ï¸ Project Structure

### Complete Directory Tree

```
F:\Python\ML Project/
â”œâ”€â”€ .gitattributes              # Git LFS tracking configuration
â”œâ”€â”€ .gitignore                  # Git ignore patterns (Python, Node, etc.)
â”œâ”€â”€ README.md                   # ğŸ“˜ This comprehensive documentation
â”œâ”€â”€ README_COMPREHENSIVE.md     # ğŸ“š Extended documentation (this file)
â”œâ”€â”€ SETUP_GUIDE.md              # ğŸ“– Step-by-step installation guide
â”œâ”€â”€ QUICK_REFERENCE.md          # âš¡ Quick command reference
â”œâ”€â”€ GIT_LFS_IMPLEMENTATION.md   # ğŸ“¦ Git LFS setup and usage guide
â”‚
â”œâ”€â”€ Backend/                    # ğŸ Python FastAPI backend service
â”‚   â”œâ”€â”€ main.py                 # FastAPI app, endpoints, middleware
â”‚   â”œâ”€â”€ service.py              # Model Manager, inference, GradCAM
â”‚   â”œâ”€â”€ check_dataset.py        # Dataset validation utility
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â”œâ”€â”€ .env                    # Environment variables (not in repo)
â”‚   â”œâ”€â”€ .gitignore              # Backend-specific git ignores
â”‚   â”œâ”€â”€ DATASET.md              # ğŸ“¥ Dataset download instructions
â”‚   â”œâ”€â”€ dataset_summary.json    # Generated dataset statistics
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                 # ğŸ§  Pre-trained model weights (Git LFS)
â”‚   â”‚   â”œâ”€â”€ __init__.py         # Python package marker
â”‚   â”‚   â”œâ”€â”€ xception.py         # Custom Xception implementation
â”‚   â”‚   â”œâ”€â”€ README.md           # ğŸ“¦ Model files & LFS guide
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ resnet50.pth        # ğŸ“¦ ResNet50 weights (98 MB, LFS)
â”‚   â”‚   â”œâ”€â”€ resnet152v2.pth     # ğŸ“¦ ResNet152V2 weights (236 MB, LFS)
â”‚   â”‚   â”œâ”€â”€ inceptionresnetv2.pth # ğŸ“¦ InceptionResNetV2 (215 MB, LFS)
â”‚   â”‚   â”œâ”€â”€ xception.pth        # ğŸ“¦ Xception weights (88 MB, LFS)
â”‚   â”‚   â”œâ”€â”€ efficientnetb4.pth  # ğŸ“¦ EfficientNetB4 (75 MB, LFS)
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ __pycache__/        # Compiled Python files
â”‚   â”‚
â”‚   â”œâ”€â”€ dataset/                # ğŸ“Š Training data (NOT in repo)
â”‚   â”‚   â”‚                       # Download from Kaggle (see DATASET.md)
â”‚   â”‚   â”œâ”€â”€ Train/
â”‚   â”‚   â”‚   â”œâ”€â”€ Fake/           # 70,001 fake images (256Ã—256)
â”‚   â”‚   â”‚   â””â”€â”€ Real/           # 70,001 real images (256Ã—256)
â”‚   â”‚   â”œâ”€â”€ Validation/
â”‚   â”‚   â”‚   â”œâ”€â”€ Fake/           # 19,641 fake images
â”‚   â”‚   â”‚   â””â”€â”€ Real/           # 19,787 real images
â”‚   â”‚   â””â”€â”€ Test/
â”‚   â”‚       â”œâ”€â”€ Fake/           # 5,492 fake images
â”‚   â”‚       â””â”€â”€ Real/           # 5,413 real images
â”‚   â”‚
â”‚   â””â”€â”€ __pycache__/            # Compiled Python files
â”‚
â””â”€â”€ Frontend/                   # âš›ï¸ React + Vite frontend application
    â”œâ”€â”€ index.html              # HTML entry point
    â”œâ”€â”€ package.json            # NPM dependencies & scripts
    â”œâ”€â”€ package-lock.json       # Locked dependency versions
    â”œâ”€â”€ vite.config.js          # Vite build configuration
    â”œâ”€â”€ eslint.config.js        # ESLint code quality rules
    â”œâ”€â”€ .env                    # Environment variables (not in repo)
    â”œâ”€â”€ README.md               # Frontend-specific documentation
    â”‚
    â”œâ”€â”€ public/                 # Static assets served directly
    â”‚   â””â”€â”€ (vite.svg, etc.)
    â”‚
    â”œâ”€â”€ src/                    # âš›ï¸ React source code
    â”‚   â”œâ”€â”€ main.jsx            # React app entry point
    â”‚   â”œâ”€â”€ App.jsx             # Root component with routing
    â”‚   â”œâ”€â”€ index.css           # Global styles
    â”‚   â”‚
    â”‚   â”œâ”€â”€ assets/             # Images, icons, media files
    â”‚   â”‚
    â”‚   â””â”€â”€ components/         # React components
    â”‚       â”‚
    â”‚       â”œâ”€â”€ HomePage.jsx    # Main page container
    â”‚       â”‚                   # - Theme provider (dark mode)
    â”‚       â”‚                   # - Layout orchestration
    â”‚       â”‚
    â”‚       â”œâ”€â”€ Navbar/
    â”‚       â”‚   â””â”€â”€ Navbar.jsx  # Navigation bar
    â”‚       â”‚                   # - GitHub repository link
    â”‚       â”‚                   # - Sticky positioning
    â”‚       â”‚
    â”‚       â””â”€â”€ ModelSection/   # ğŸ¯ Main analysis interface
    â”‚           â”œâ”€â”€ index.js    # Component exports
    â”‚           â”œâ”€â”€ ModelSection.jsx      # Main container
    â”‚           â”‚                         # - Model selector
    â”‚           â”‚                         # - Layout management
    â”‚           â”‚
    â”‚           â”œâ”€â”€ ImageUploadArea.jsx   # Upload interface
    â”‚           â”‚                         # - Drag & drop
    â”‚           â”‚                         # - File picker
    â”‚           â”‚
    â”‚           â”œâ”€â”€ ImageDisplay.jsx      # Original image
    â”‚           â”‚                         # - Preview display
    â”‚           â”‚                         # - Reset button
    â”‚           â”‚
    â”‚           â”œâ”€â”€ HeatmapDisplay.jsx    # Heatmap visualization
    â”‚           â”‚                         # - GradCAM overlay
    â”‚           â”‚                         # - Prediction badge
    â”‚           â”‚                         # - Confidence display
    â”‚           â”‚
    â”‚           â”œâ”€â”€ ExplanationBox.jsx    # AI explanation
    â”‚           â”‚                         # - Color-coded styling
    â”‚           â”‚                         # - Explanation text
    â”‚           â”‚
    â”‚           â”œâ”€â”€ RealImageMessage.jsx  # Success message
    â”‚           â”‚                         # - Real image feedback
    â”‚           â”‚
    â”‚           â”œâ”€â”€ WaitingState.jsx      # Loading state
    â”‚           â”‚                         # - Analysis progress
    â”‚           â”‚
    â”‚           â””â”€â”€ hooks/
    â”‚               â””â”€â”€ useImageAnalysis.js  # Custom React hook
    â”‚                                        # - State management
    â”‚                                        # - API communication
    â”‚                                        # - File handling
    â”‚
    â”œâ”€â”€ dist/                   # Production build output (generated)
    â””â”€â”€ node_modules/           # NPM packages (generated, not in repo)
```

### File Count Summary

| Category                 | Count   | Description                                        |
| ------------------------ | ------- | -------------------------------------------------- |
| **Python Files**         | 4       | main.py, service.py, check_dataset.py, xception.py |
| **JavaScript/JSX Files** | 13      | React components and configuration                 |
| **Model Files**          | 5       | Pre-trained weights (Git LFS)                      |
| **Configuration Files**  | 8       | package.json, vite.config.js, .env, etc.           |
| **Documentation Files**  | 8       | README, guides, references                         |
| **Dataset Images**       | 190,335 | Not in repository, download separately             |

### Key Directories

#### Backend/

- **Purpose**: Python-based API server for model inference
- **Framework**: FastAPI + Uvicorn ASGI
- **Key Files**:
  - `main.py`: API endpoints, routing, CORS middleware
  - `service.py`: Core ML logic, model management, GradCAM
  - `check_dataset.py`: Dataset validation and statistics
- **Dependencies**: Listed in `requirements.txt`

#### Backend/models/

- **Purpose**: Pre-trained deep learning model weights
- **Storage**: Git LFS (Large File Storage)
- **Total Size**: ~712 MB (combined)
- **Tracked Files**: All `.pth` files automatically tracked
- **Note**: Requires Git LFS installation to download

#### Backend/dataset/

- **Purpose**: Training, validation, and test images
- **Status**: NOT included in repository
- **Download**: Required from Kaggle (see DATASET.md)
- **Size**: ~5.2 GB total
- **Structure**: Train/Val/Test splits with Fake/Real classes

#### Frontend/

- **Purpose**: User interface for image analysis
- **Framework**: React 19 + Vite + Material-UI
- **Key Files**:
  - `src/App.jsx`: Router setup
  - `src/components/HomePage.jsx`: Main layout
  - `src/components/ModelSection/ModelSection.jsx`: Analysis UI
  - `src/components/ModelSection/hooks/useImageAnalysis.js`: Logic hook
- **Dependencies**: Listed in `package.json`

#### Frontend/src/components/

- **Purpose**: Modular React components
- **Organization**: Feature-based grouping
- **Patterns**:
  - Component co-location (styles, logic, UI together)
  - Custom hooks for reusable logic
  - PropTypes for type checking
  - Material-UI theming

### Architecture Patterns

1. **Backend (Python)**:

   - **Singleton Pattern**: ModelManager class (single instance)
   - **Factory Pattern**: Model building based on string identifier
   - **Strategy Pattern**: Different preprocessing per model
   - **Dependency Injection**: Device, checkpoints configurable
   - **Error Handling**: Try-catch with logging, HTTP status codes

2. **Frontend (React)**:

   - **Component Composition**: Small, reusable components
   - **Custom Hooks**: useImageAnalysis for complex logic
   - **State Management**: React useState, useCallback, useEffect
   - **Prop Drilling Avoidance**: Hooks centralize state
   - **Responsive Design**: Mobile-first with breakpoints

3. **API Design**:
   - **RESTful**: Resource-based URLs (/models/, /predict/)
   - **Stateless**: Each request independent
   - **JSON**: Standard data format
   - **CORS**: Secure cross-origin access
   - **Versioning Ready**: URL structure allows /v1/, /v2/, etc.

## ğŸ› ï¸ Technical Stack

### Backend Technologies

#### Core Framework

| Technology   | Version              | Purpose                         |
| ------------ | -------------------- | ------------------------------- |
| **Python**   | 3.8+                 | Primary programming language    |
| **FastAPI**  | 0.100+               | Modern async web framework      |
| **Uvicorn**  | 0.23+                | ASGI server for FastAPI         |
| **Pydantic** | (FastAPI dependency) | Data validation & serialization |

#### Deep Learning

| Technology      | Version | Purpose                         |
| --------------- | ------- | ------------------------------- |
| **PyTorch**     | 2.0+    | Deep learning framework         |
| **TorchVision** | 0.15+   | Pre-trained models & transforms |
| **timm**        | Latest  | PyTorch Image Models library    |
| **TorchCAM**    | 0.3+    | GradCAM implementation          |

#### Computer Vision & Image Processing

| Technology                 | Version | Purpose                       |
| -------------------------- | ------- | ----------------------------- |
| **OpenCV (opencv-python)** | 4.8+    | Image manipulation & heatmaps |
| **Pillow (PIL)**           | 9.0+    | Image loading & conversion    |
| **NumPy**                  | 1.21+   | Numerical operations          |

#### AI & LLM Integration

| Technology              | Version | Purpose           |
| ----------------------- | ------- | ----------------- |
| **google-generativeai** | 0.3+    | Gemini API client |

#### Data Science & Analysis

| Technology       | Version | Purpose                              |
| ---------------- | ------- | ------------------------------------ |
| **Pandas**       | 2.0+    | Data manipulation                    |
| **scikit-learn** | 1.0+    | ML utilities                         |
| **Matplotlib**   | 3.5+    | Visualization (optional)             |
| **Seaborn**      | 0.11+   | Statistical visualization (optional) |
| **tqdm**         | 4.64+   | Progress bars                        |

#### Utilities

| Technology           | Version | Purpose                         |
| -------------------- | ------- | ------------------------------- |
| **python-dotenv**    | 1.0+    | Environment variable management |
| **python-multipart** | 0.0.6+  | Multipart form data parsing     |

### Frontend Technologies

#### Core Framework

| Technology                   | Version | Purpose                     |
| ---------------------------- | ------- | --------------------------- |
| **React**                    | 19.1.1  | UI library                  |
| **React DOM**                | 19.1.1  | React renderer              |
| **Vite**                     | 7.1.6   | Build tool & dev server     |
| **@vitejs/plugin-react-swc** | 4.0.1   | Fast React refresh with SWC |

#### UI Library

| Technology                      | Version | Purpose           |
| ------------------------------- | ------- | ----------------- |
| **Material-UI (@mui/material)** | 7.3.2   | Component library |
| **@mui/icons-material**         | 7.3.2   | Icon library      |
| **@emotion/react**              | 11.14.0 | CSS-in-JS styling |
| **@emotion/styled**             | 11.14.1 | Styled components |

#### Routing

| Technology           | Version | Purpose             |
| -------------------- | ------- | ------------------- |
| **React Router DOM** | 7.9.1   | Client-side routing |

#### Code Quality & Linting

| Technology                      | Version | Purpose                     |
| ------------------------------- | ------- | --------------------------- |
| **ESLint**                      | 9.35.0  | JavaScript linting          |
| **@eslint/js**                  | 9.35.0  | ESLint core                 |
| **eslint-plugin-react-hooks**   | 5.2.0   | React hooks linting         |
| **eslint-plugin-react-refresh** | 0.4.20  | React refresh linting       |
| **globals**                     | 16.4.0  | Global variables definition |

#### TypeScript (Type Checking)

| Technology           | Version | Purpose                    |
| -------------------- | ------- | -------------------------- |
| **@types/react**     | 19.1.13 | React type definitions     |
| **@types/react-dom** | 19.1.9  | React DOM type definitions |

### Development Tools

#### Version Control

| Tool        | Purpose                       |
| ----------- | ----------------------------- |
| **Git**     | Source code version control   |
| **Git LFS** | Large file storage for models |
| **GitHub**  | Code hosting & collaboration  |

#### Environment Management

| Tool            | Purpose                    |
| --------------- | -------------------------- |
| **Python venv** | Python virtual environment |
| **Node.js**     | JavaScript runtime         |
| **npm**         | Node package manager       |

#### API Testing

| Tool                   | Purpose                       |
| ---------------------- | ----------------------------- |
| **FastAPI Swagger UI** | Interactive API documentation |
| **Redoc**              | Alternative API documentation |
| **curl**               | Command-line API testing      |

### External Services

#### APIs

| Service                     | Purpose                       |
| --------------------------- | ----------------------------- |
| **Google Gemini 2.5 Flash** | Natural language explanations |
| **Kaggle API**              | Dataset download              |

### Infrastructure (Recommended)

#### Compute

| Resource    | Recommended            | Purpose                   |
| ----------- | ---------------------- | ------------------------- |
| **CPU**     | 4+ cores               | Backend processing        |
| **RAM**     | 16 GB+                 | Model loading & inference |
| **GPU**     | NVIDIA CUDA-compatible | Accelerated inference     |
| **VRAM**    | 8 GB+                  | GPU model loading         |
| **Storage** | 20 GB+                 | Models + dataset          |

#### Deployment Options

| Platform              | Use Case                         |
| --------------------- | -------------------------------- |
| **Docker**            | Containerized deployment         |
| **AWS EC2**           | Cloud compute instance           |
| **Google Cloud Run**  | Serverless container deployment  |
| **Azure App Service** | Managed web hosting              |
| **Heroku**            | Simple cloud deployment          |
| **Vercel**            | Frontend hosting (Frontend only) |
| **Netlify**           | Frontend hosting (Frontend only) |

### Browser Compatibility

| Browser     | Minimum Version |
| ----------- | --------------- |
| **Chrome**  | 90+             |
| **Firefox** | 88+             |
| **Safari**  | 14+             |
| **Edge**    | 90+             |

### Operating System Compatibility

| OS          | Status                              |
| ----------- | ----------------------------------- |
| **Windows** | âœ… Tested (10, 11)                  |
| **macOS**   | âœ… Compatible (10.15+)              |
| **Linux**   | âœ… Compatible (Ubuntu 20.04+, etc.) |

---

## ğŸ“ˆ Performance Metrics

### Individual Model Performance

Comprehensive training and validation metrics for all models in the ensemble:

| Model                 | Train Accuracy | Train Loss | Val Accuracy | Val Loss   | Generalization Gap |
| --------------------- | -------------- | ---------- | ------------ | ---------- | ------------------ |
| **EfficientNetB4**    | **99.82%**     | 0.0050     | 98.68%       | 0.0787     | 1.14%              |
| **InceptionResNetV2** | **99.62%**     | 0.0093     | **98.88%**   | 0.0441     | **0.74%**          |
| **ResNet152V2**       | **99.72%**     | 0.0085     | 98.87%       | 0.0506     | 0.85%              |
| **Xception**          | 99.41%         | **0.0048** | 98.79%       | 0.0658     | 0.62%              |
| **ResNet50**          | 99.18%         | 0.0206     | 98.57%       | 0.0438     | 0.61%              |
| **Average**           | **99.55%**     | **0.0096** | **98.76%**   | **0.0566** | **0.79%**          |

### Performance Analysis

#### Accuracy Metrics

- **Training Accuracy Range**: 99.18% - 99.82%
  - Highest: EfficientNetB4 (99.82%)
  - Lowest: ResNet50 (99.18%)
  - Spread: 0.64%
- **Validation Accuracy Range**: 98.57% - 98.88%

  - Highest: InceptionResNetV2 (98.88%)
  - Lowest: ResNet50 (98.57%)
  - Spread: 0.31%

- **Average Performance**:
  - Training: 99.55%
  - Validation: 98.76%
  - All models exceed 98.5% validation accuracy

#### Loss Metrics

- **Training Loss Range**: 0.0048 - 0.0206
  - Lowest: Xception (0.0048) - best convergence
  - Highest: ResNet50 (0.0206)
  - Average: 0.0096
- **Validation Loss Range**: 0.0438 - 0.0787
  - Lowest: ResNet50 (0.0438)
  - Highest: EfficientNetB4 (0.0787)
  - Average: 0.0566

#### Overfitting Analysis

- **Generalization Gap**: 0.61% - 1.14%

  - Best: ResNet50 (0.61%) - excellent generalization
  - Worst: EfficientNetB4 (1.14%) - still very good
  - Average: 0.79% - minimal overfitting across all models

- **Overfitting Classification**:
  - **Excellent** (<0.75%): ResNet50, Xception
  - **Very Good** (0.75%-1.0%): InceptionResNetV2, ResNet152V2
  - **Good** (1.0%-1.5%): EfficientNetB4

### Ensemble Performance Advantages

The ensemble approach combines these individual models for superior performance:

1. **Diversity**: Different architectures capture different feature patterns

   - ResNet: Deep residual connections
   - Inception: Multi-scale feature extraction
   - Xception: Depthwise separable convolutions
   - EfficientNet: Compound scaling

2. **Error Reduction**: Individual model biases cancel out through averaging

   - Expected ensemble accuracy: >99.0%
   - Reduced variance in predictions
   - More robust to edge cases

3. **Confidence Calibration**: Ensemble probabilities are better calibrated

   - Weighted averaging based on per-model confidence
   - More reliable uncertainty estimation
   - Better decision thresholds

4. **Complementary Strengths**:
   - InceptionResNetV2: Best validation accuracy (98.88%)
   - EfficientNetB4: Highest training accuracy (99.82%)
   - Xception: Lowest training loss (0.0048)
   - ResNet50: Best generalization (0.61% gap)
   - ResNet152V2: Balanced performance (99.72% train, 98.87% val)

### Inference Performance

| Metric                            | GPU (CUDA) | CPU     |
| --------------------------------- | ---------- | ------- |
| **Single Model Inference**        | ~0.4-1.0s  | ~2-4s   |
| **Ensemble Inference (5 models)** | ~2-5s      | ~10-20s |
| **GradCAM Generation**            | ~0.2-0.5s  | ~1-2s   |
| **Total Processing Time**         | ~2.5-6s    | ~11-22s |
| **Throughput (images/minute)**    | ~10-24     | ~3-5    |

**Note**: Times vary based on:

- Input image size
- Hardware specifications
- Model selection (ensemble vs individual)
- GradCAM computation enabled/disabled

### Model Comparison Insights

**Best for Speed**: ResNet50

- Smallest model (25.6M parameters)
- Fastest inference time
- Good accuracy (98.57% validation)

**Best for Accuracy**: InceptionResNetV2

- Highest validation accuracy (98.88%)
- Low validation loss (0.0441)
- Excellent generalization (0.74% gap)

**Best for Generalization**: ResNet50 & Xception

- Minimal overfitting (<0.65% gap)
- Stable performance across train/val
- Reliable predictions

**Most Powerful**: ResNet152V2

- Largest model (60.2M parameters)
- Excellent all-around performance (99.72% train, 98.87% val)
- Strong feature extraction

**Most Efficient**: EfficientNetB4

- Best parameter efficiency (19.3M params)
- Highest training accuracy (99.82%)
- Compound scaling advantages

### Dataset Performance Statistics

**Training Set** (140,002 images):

- Average accuracy across all models: **99.55%**
- Images correctly classified: ~139,372
- Images misclassified: ~630

**Validation Set** (39,428 images):

- Average accuracy across all models: **98.76%**
- Images correctly classified: ~38,939
- Images misclassified: ~489

**Expected Test Set Performance** (10,905 images):

- Estimated accuracy: **98.5% - 99.0%**
- Expected correct classifications: ~10,740-10,796
- Expected misclassifications: ~109-165

### Performance Optimization

Techniques used to achieve these results:

1. **Data Augmentation**: Enhanced training diversity
2. **Transfer Learning**: Leveraged ImageNet pre-training
3. **Fine-tuning**: Task-specific adaptation
4. **Regularization**: Dropout, weight decay
5. **Learning Rate Scheduling**: Optimal convergence
6. **Early Stopping**: Prevented overfitting
7. **Ensemble Averaging**: Combined model strengths

---

**Continue to [Installation](#-installation) â†’**
